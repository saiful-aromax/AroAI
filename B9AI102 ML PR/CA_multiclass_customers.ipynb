{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "use diamonds dataset to predict **price** in terms of other variables. For this, \n",
    "a. estimate the parameters\n",
    "b. select the imporant input features \n",
    "c. write down the predictive model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since price is practically continous therefore we need to apply linear regression:\n",
    "to do the following tasks:\n",
    "1.   parameter learning\n",
    "2.   feature selection\n",
    "3.   predictive model (use steps 1 and 2 and link function)\n",
    "4.   prediction \n",
    "5.   Evaluate the performance of prediction (split the dataset into trainset and testset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do Linear regression using 2 different ways:\n",
    "1.  using statistical learning\n",
    "2.  using sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data modeling:\n",
    "1. import the function of the model\n",
    "2. create the model\n",
    "3.  fit the model\n",
    "4. prediction using the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical way to recall GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import neccessary library\n",
    "from statistics import mean\n",
    "from statsmodels.api import GLM, add_constant, families\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('dataset/diamonds.csv')\n",
    "\n",
    "X = data.drop(['price', 'Unnamed: 0'], axis=1)  # Input variables\n",
    "y = data['price']  # Output variable\n",
    "\n",
    "OE = OrdinalEncoder(categories=[['Fair', 'Good', 'Very Good', 'Ideal', 'Premium']])\n",
    "\n",
    "data_cut_OE = OE.fit_transform(X[['cut']])\n",
    "data_cut_DF = DataFrame(data_cut_OE)\n",
    "data_cut_DF.columns = ['encoded cut']\n",
    "\n",
    "OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "data_color_OHE = OHE.fit_transform(X[['color']])\n",
    "data_color_DF = DataFrame(data_color_OHE.toarray())\n",
    "data_color_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "data_clarity_OHE = OHE.fit_transform(X[['clarity']])\n",
    "data_clarity_DF = DataFrame(data_clarity_OHE.toarray())\n",
    "data_clarity_DF.columns = OHE.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging multiple DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = concat([data_color_DF, data_clarity_DF], axis=1) # Excluding data_cut_DF since it is ordinal\n",
    "X_scalable = X[['carat', 'depth', 'table', 'length_mm', 'width_mm', 'depth_mm']]  # Orginal numeric columns\n",
    "X_scalable = concat([X_scalable, data_cut_DF], axis=1)  # Including encoded ordinal columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X_scalable)\n",
    "X_scaled_DF = DataFrame(X_scaled)\n",
    "X_scaled_DF.columns = X_scalable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>length_mm</th>\n",
       "      <th>width_mm</th>\n",
       "      <th>depth_mm</th>\n",
       "      <th>encoded cut</th>\n",
       "      <th>color_D</th>\n",
       "      <th>color_E</th>\n",
       "      <th>color_F</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_I1</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.206418</td>\n",
       "      <td>-0.107785</td>\n",
       "      <td>-1.142937</td>\n",
       "      <td>-2.460814</td>\n",
       "      <td>-2.455435</td>\n",
       "      <td>-2.465387</td>\n",
       "      <td>0.225867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.305673</td>\n",
       "      <td>-1.092137</td>\n",
       "      <td>1.333186</td>\n",
       "      <td>-2.552417</td>\n",
       "      <td>-2.673932</td>\n",
       "      <td>-2.761965</td>\n",
       "      <td>1.099829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.206418</td>\n",
       "      <td>-2.771325</td>\n",
       "      <td>2.983935</td>\n",
       "      <td>-2.308143</td>\n",
       "      <td>-2.314972</td>\n",
       "      <td>-2.761965</td>\n",
       "      <td>-1.522057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.908655</td>\n",
       "      <td>0.413343</td>\n",
       "      <td>0.095125</td>\n",
       "      <td>-2.079136</td>\n",
       "      <td>-2.065261</td>\n",
       "      <td>-1.971090</td>\n",
       "      <td>1.099829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.809400</td>\n",
       "      <td>0.934470</td>\n",
       "      <td>0.095125</td>\n",
       "      <td>-1.865396</td>\n",
       "      <td>-1.877977</td>\n",
       "      <td>-1.674511</td>\n",
       "      <td>-1.522057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>0.225316</td>\n",
       "      <td>-0.107785</td>\n",
       "      <td>-0.730250</td>\n",
       "      <td>0.241466</td>\n",
       "      <td>0.369425</td>\n",
       "      <td>0.277963</td>\n",
       "      <td>0.225867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>0.721588</td>\n",
       "      <td>-1.265846</td>\n",
       "      <td>-0.317563</td>\n",
       "      <td>0.852150</td>\n",
       "      <td>0.837634</td>\n",
       "      <td>0.500397</td>\n",
       "      <td>0.225867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0.274943</td>\n",
       "      <td>-0.223591</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.378870</td>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>1.099829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>1.813387</td>\n",
       "      <td>-0.049882</td>\n",
       "      <td>1.333186</td>\n",
       "      <td>1.386500</td>\n",
       "      <td>1.399485</td>\n",
       "      <td>1.365417</td>\n",
       "      <td>1.099829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>0.274943</td>\n",
       "      <td>-0.223591</td>\n",
       "      <td>0.095125</td>\n",
       "      <td>0.302534</td>\n",
       "      <td>0.431853</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>-0.648095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>859 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        carat     depth     table  length_mm  width_mm  depth_mm  encoded cut  \\\n",
       "0   -2.206418 -0.107785 -1.142937  -2.460814 -2.455435 -2.465387     0.225867   \n",
       "1   -2.305673 -1.092137  1.333186  -2.552417 -2.673932 -2.761965     1.099829   \n",
       "2   -2.206418 -2.771325  2.983935  -2.308143 -2.314972 -2.761965    -1.522057   \n",
       "3   -1.908655  0.413343  0.095125  -2.079136 -2.065261 -1.971090     1.099829   \n",
       "4   -1.809400  0.934470  0.095125  -1.865396 -1.877977 -1.674511    -1.522057   \n",
       "..        ...       ...       ...        ...       ...       ...          ...   \n",
       "854  0.225316 -0.107785 -0.730250   0.241466  0.369425  0.277963     0.225867   \n",
       "855  0.721588 -1.265846 -0.317563   0.852150  0.837634  0.500397     0.225867   \n",
       "856  0.274943 -0.223591  0.507812   0.378870  0.353818  0.302678     1.099829   \n",
       "857  1.813387 -0.049882  1.333186   1.386500  1.399485  1.365417     1.099829   \n",
       "858  0.274943 -0.223591  0.095125   0.302534  0.431853  0.302678    -0.648095   \n",
       "\n",
       "     color_D  color_E  color_F  ...  color_I  color_J  clarity_I1  clarity_IF  \\\n",
       "0        0.0      1.0      0.0  ...      0.0      0.0         0.0         0.0   \n",
       "1        0.0      1.0      0.0  ...      0.0      0.0         0.0         0.0   \n",
       "2        0.0      1.0      0.0  ...      0.0      0.0         0.0         0.0   \n",
       "3        0.0      0.0      0.0  ...      1.0      0.0         0.0         0.0   \n",
       "4        0.0      0.0      0.0  ...      0.0      1.0         0.0         0.0   \n",
       "..       ...      ...      ...  ...      ...      ...         ...         ...   \n",
       "854      0.0      0.0      1.0  ...      0.0      0.0         0.0         0.0   \n",
       "855      0.0      0.0      0.0  ...      0.0      0.0         0.0         0.0   \n",
       "856      0.0      1.0      0.0  ...      0.0      0.0         0.0         0.0   \n",
       "857      0.0      0.0      0.0  ...      1.0      0.0         1.0         0.0   \n",
       "858      0.0      1.0      0.0  ...      0.0      0.0         0.0         0.0   \n",
       "\n",
       "     clarity_SI1  clarity_SI2  clarity_VS1  clarity_VS2  clarity_VVS1  \\\n",
       "0            0.0          1.0          0.0          0.0           0.0   \n",
       "1            1.0          0.0          0.0          0.0           0.0   \n",
       "2            0.0          0.0          1.0          0.0           0.0   \n",
       "3            0.0          0.0          0.0          1.0           0.0   \n",
       "4            0.0          1.0          0.0          0.0           0.0   \n",
       "..           ...          ...          ...          ...           ...   \n",
       "854          1.0          0.0          0.0          0.0           0.0   \n",
       "855          0.0          0.0          0.0          1.0           0.0   \n",
       "856          0.0          0.0          1.0          0.0           0.0   \n",
       "857          0.0          0.0          0.0          0.0           0.0   \n",
       "858          1.0          0.0          0.0          0.0           0.0   \n",
       "\n",
       "     clarity_VVS2  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "..            ...  \n",
       "854           0.0  \n",
       "855           0.0  \n",
       "856           0.0  \n",
       "857           0.0  \n",
       "858           0.0  \n",
       "\n",
       "[859 rows x 22 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_PREP = concat([X_scaled_DF, X_binary], axis=1)  # Prepared Data\n",
    "X_PREP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling for feature selection / reduced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(X_PREP)  # Ading constant column to handle bias; \n",
    "model_full = GLM(y, X, family=families.Gaussian(families.links.log())).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = dict(model_full.pvalues)  # Identifying the columns to drop\n",
    "drop_columns = []\n",
    "for x in pvalues:\n",
    "    if pvalues[x] >= 0.05:\n",
    "        drop_columns.append(x)\n",
    "# print(drop_columns)\n",
    "X_red = X.drop(drop_columns, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive Model:  yhat=5.455245+0.001909*ZN+0.022373*INDUS+0.028275*RAD-0.002238*MEDV    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[225.3099879525569, 228.72941658063053]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_full = []\n",
    "rmse_red = []\n",
    "for i in range(20):\n",
    "    X = add_constant(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    #*************Full Data Modelling*************\n",
    "    \n",
    "    # Creating the Linear Regression Model\n",
    "    model_full = GLM(y_train, X_train, family=families.Gaussian(families.links.log())).fit()\n",
    "\n",
    "    # Predicting using Test-set\n",
    "    pred_full = model_full.predict(X_test)\n",
    "    rmse_full.append(sqrt(mean_squared_error(y_test, pred_full)))\n",
    "    \n",
    "    #*************Reduced Data Modelling*************\n",
    "    \n",
    "    # Creating the Linear Regression Model\n",
    "    X = add_constant(X_red)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model_reduced = GLM(y_train, X_train, family=families.Gaussian(families.links.log())).fit()\n",
    "    \n",
    "    # Predicting using Test-set\n",
    "    pred_red = model_reduced.predict(X_test)\n",
    "    rmse_red.append(sqrt(mean_squared_error(y_test, pred_red)))\n",
    "\n",
    "[mean(rmse_full), mean(rmse_red)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(X_red)\n",
    "model_dep = GLM(y, X, family=families.Gaussian(families.links.log())).fit()  # create the linear reg model using"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858    2824.675874\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "858    2871\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = X.tail(1)\n",
    "pred_red = model_dep.predict(new)\n",
    "print(pred_red)\n",
    "y.tail(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical & sklearn way to recall GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary library\n",
    "from statistics import mean\n",
    "from statsmodels.api import GLM, add_constant, families\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'length_mm', 'width_mm', 'depth_mm']\n",
      "<class 'pandas.core.indexes.base.Index'>\n"
     ]
    }
   ],
   "source": [
    "data = read_csv('dataset/diamonds.csv')\n",
    "\n",
    "X = data.drop(['price', 'Unnamed: 0'], axis=1)  # Input variables\n",
    "y = data['price']  # Output variable\n",
    "\n",
    "OE = OrdinalEncoder(categories=[['Fair', 'Good', 'Very Good', 'Ideal', 'Premium']])\n",
    "data_cut_OE = OE.fit_transform(X[['cut']])\n",
    "data_cut_DF = DataFrame(data_cut_OE)\n",
    "data_cut_DF.columns = ['encoded cut']\n",
    "\n",
    "OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "data_color_OHE = OHE.fit_transform(X[['color']])\n",
    "data_color_DF = DataFrame(data_color_OHE.toarray())\n",
    "data_color_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "data_clarity_OHE = OHE.fit_transform(X[['clarity']])\n",
    "data_clarity_DF = DataFrame(data_clarity_OHE.toarray())\n",
    "data_clarity_DF.columns = OHE.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging multiple DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = concat([data_color_DF, data_clarity_DF], axis=1) # Excluding data_cut_DF since it is ordinal\n",
    "X_scalable = X[['carat', 'depth', 'table', 'length_mm', 'width_mm', 'depth_mm']]  # Orginal numeric columns\n",
    "X_scalable = concat([X_scalable, data_cut_DF], axis=1) # Including encoded ordinal columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying standard scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X_scalable)\n",
    "X_scaled_DF = DataFrame(X_scaled)\n",
    "X_scaled_DF.columns = X_scalable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PREP = concat([X_scaled_DF, X_binary], axis=1)  # Prepared Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling for feature selection / reduced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(X_PREP)  # Ading constant column to handle bias\n",
    "model_full = GLM(y, X, family=families.Gaussian(families.links.log())).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = dict(model_full.pvalues)  # Identifying the columns to drop\n",
    "drop_columns = []\n",
    "for x in pvalues:\n",
    "    if pvalues[x] >= 0.05:\n",
    "        drop_columns.append(x)\n",
    "# print(drop_columns)\n",
    "X_red = X.drop(drop_columns, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive Model:  yhat=5.455245+0.001909*ZN+0.022373*INDUS+0.028275*RAD-0.002238*MEDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[231.3826222352573, 221.00936319241126, 164.57963498013402, 158.71981793809638]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_st_full = []\n",
    "rmse_st_red = []\n",
    "rmse_skl_full = []\n",
    "rmse_skl_red = []\n",
    "\n",
    "model_skl = LinearRegression()\n",
    "for i in range(20):\n",
    "    #************************* Full Data Modelling  ***************************#\n",
    "    X = add_constant(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # statsmodels\n",
    "    model_st_full = GLM(y_train, X_train, family=families.Gaussian(families.links.log())).fit()\n",
    "\n",
    "    # Predicting using Test-set\n",
    "    pred_st_full = model_st_full.predict(X_test)\n",
    "    rmse_st_full.append(sqrt(mean_squared_error(y_test, pred_st_full)))\n",
    "    \n",
    "    # sklearn\n",
    "    model_skl.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting using Test-set\n",
    "    pred_skl_full = model_skl.predict(X_test)\n",
    "    rmse_skl_full.append(sqrt(mean_squared_error(y_test, pred_skl_full)))\n",
    "    \n",
    "    #************************* Reduced Data Modelling  ***************************#\n",
    "    X = add_constant(X_red)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # statsmodels\n",
    "    model_st_red = GLM(y_train, X_train, family=families.Gaussian(families.links.log())).fit()  # create the linear reg model using\n",
    "    \n",
    "    # Predicting using Test-set\n",
    "    pred_red = model_reduced.predict(X_test)\n",
    "    rmse_st_red.append(sqrt(mean_squared_error(y_test, pred_red)))\n",
    "    \n",
    "    # sklearn\n",
    "    model_skl.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting using Test-set\n",
    "    pred_skl_red = model_skl.predict(X_test)\n",
    "    rmse_skl_red.append(sqrt(mean_squared_error(y_test, pred_skl_red)))\n",
    "    \n",
    "\n",
    "[mean(rmse_st_full), mean(rmse_st_red), mean(rmse_skl_full), mean(rmse_skl_red)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(X_red)\n",
    "model_skl_red_dep = model_skl.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using Test-set\n",
    "# Predict the tax using the linear regression for the last row in the boston_house-prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2809.03468253]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "858    2871\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model_skl_red_dep.predict(X.tail(1))\n",
    "print(prediction)\n",
    "y.tail(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "Use boston_house price dataset, \n",
    "1.   Consider CHAS as the output variable \n",
    "2.   the remaining variables are inputs \n",
    "apply logistic regression to do the following tasks:\n",
    "*  parameter estimation \n",
    "*   attribute selection \n",
    "*  predictive model\n",
    "*   prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary library\n",
    "from statistics import mean\n",
    "from statsmodels.api import GLM, add_constant, families\n",
    "from pandas import read_csv, DataFrame\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import accuracy_score, recall_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_csv('dataset_CA/heart.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('output', axis=1)  # input\n",
    "y = data['output']   # output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling for feature selection / reduced model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(X)  # add intercept\n",
    "model_st = GLM(y, X, family=families.Binomial()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to be romoved: ['const', 'age', 'trtbps', 'chol', 'fbs', 'restecg', 'slp']\n"
     ]
    }
   ],
   "source": [
    "pvalues = dict(model_st.pvalues)  # Identifying the columns to drop\n",
    "drop_columns = []\n",
    "for x in pvalues:\n",
    "    if pvalues[x] >= 0.05:\n",
    "        drop_columns.append(x)\n",
    "print(\"Columns to be romoved:\", drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = X.drop(drop_columns, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=3)  # testset is 10%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive model based on above results:\n",
    "\n",
    "that_i = 0.0952 * INDUS_i + 0.2191 * RAD_i - 0.0087 * TAX_i + 0.0693 * MEDV_i\n",
    "\n",
    "1.   phat_i = 1 / (1 + exp(-that_i))\n",
    "2.   yhat_i = 1 if phat_i >= 0.5 else yhat_i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_st_red = GLM(y_train, X_train, family=families.Binomial()).fit() # logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_st_raw = model_st_red.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting predictions to binary predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction  Actual\n",
       "245           0       0\n",
       "162           1       1\n",
       "10            1       1\n",
       "161           1       1\n",
       "73            1       1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_st = [1 if prediction > 0.5 else 0 for prediction in prediction_st_raw]\n",
    "df = DataFrame({\"Prediction\": prediction_st, \"Actual\": y_test})\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_skl = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "prediction_skl = model_skl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction  Actual\n",
       "245           0       0\n",
       "162           1       1\n",
       "10            1       1\n",
       "161           1       1\n",
       "73            1       1\n",
       "16            1       1\n",
       "180           0       0\n",
       "195           0       0\n",
       "200           1       0\n",
       "47            1       1\n",
       "101           0       1\n",
       "190           0       0\n",
       "79            1       1\n",
       "179           0       0\n",
       "269           0       0\n",
       "84            1       1\n",
       "77            1       1\n",
       "252           0       0\n",
       "38            1       1\n",
       "114           1       1\n",
       "225           0       0\n",
       "127           1       1\n",
       "78            1       1\n",
       "261           1       0\n",
       "67            1       1\n",
       "14            1       1\n",
       "123           1       1\n",
       "25            1       1\n",
       "65            1       1\n",
       "215           0       0\n",
       "222           1       0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame({'Prediction': prediction_skl, \"Actual\": y_test})\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute recall and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8709677419354839, 0.8709677419354839]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9473684210526315, 0.9473684210526315]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction_st\n",
    "acc_st = accuracy_score(y_test, prediction_st)\n",
    "re_st = recall_score(y_test, prediction_st)\n",
    "acc_skl = accuracy_score(y_test, prediction_skl)\n",
    "re_skl = recall_score(y_test, prediction_skl)\n",
    "print([acc_st, acc_skl])\n",
    "[re_st, re_skl]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Example\n",
    "\n",
    "Use **winequality-red** dataset, apply NB classifier to predict **quality** variable. to do so, \n",
    "\n",
    "1. split the dataset into 70/30%\n",
    "\n",
    "2. evaluate the model using **accurary** and **recall**.\n",
    "\n",
    "3. validate the result using MC sampling with mc=100. \n",
    "\n",
    "4. predict the quality for a give set of input variables. \n",
    "\n",
    "5. redo the classification task using logistic regression and compare the result versus Naive Bayes classifier in 100 MC runs. Specify the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mdataset_CA/Customers.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m X \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# input\u001b[39;00m\n\u001b[0;32m      3\u001b[0m y \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m]   \u001b[39m# output\u001b[39;00m\n\u001b[0;32m      4\u001b[0m y\u001b[39m.\u001b[39mvalue_counts()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset_CA/Customers.csv')\n",
    "X = data.drop('output', axis=1)  # input\n",
    "y = data['output']   # output\n",
    "y.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction  Actual\n",
       "105           1       1\n",
       "154           1       1\n",
       "133           1       1\n",
       "223           0       0\n",
       "198           0       0\n",
       "..          ...     ...\n",
       "82            1       1\n",
       "108           1       1\n",
       "249           0       0\n",
       "176           0       0\n",
       "211           0       0\n",
       "\n",
       "[61 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # 70% training and 30% testgnb = GaussianNB()\n",
    "gnb = GaussianNB().fit(X_train, y_train) # Train the model using the training sets\n",
    "\n",
    "prediction = gnb.predict(X_test)  # Predict the response for test dataset\n",
    "df = DataFrame({'Prediction': prediction, \"Actual\": y_test})\n",
    "df\n",
    "# accuracy = accuracy_score(y_test, prediction)\n",
    "# recall = recall_score(y_test, prediction, average='micro')\n",
    "# [accuracy, recall]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation using Monte Calro sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8168791208791211"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "for r in range(1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    gnb = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "    prediction = gnb.predict(X_test)  # Predict the response for test dataset\n",
    "    accuracy.append(accuracy_score(y_test, prediction))\n",
    "mean(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation based on Cross Validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8118464621819449"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "scores = cross_val_score(gnb, X, y, cv=2)\n",
    "mean(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction: for the last sample in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input = X.tail(1)\n",
    "gnb.fit(X, y)\n",
    "gnb.predict(X_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Use iris dataset\n",
    "1.  Fit the Naive Bayes classifier  and evaluate the accuracy of the model in 100 mc runs. use 80% as the trainset and 20% testset.\n",
    "2.  Recommend the type of flower for the following sample: X=[4,1,2,3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('dataset_CA/c2k_data_comma.csv')\n",
    "X = data.drop('legs', axis=1)  # input\n",
    "y = data['legs']   # output\n",
    "# y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '?'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[0;32m      4\u001b[0m     X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39mi)\n\u001b[1;32m----> 5\u001b[0m     gnb\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      6\u001b[0m     prediction \u001b[39m=\u001b[39m gnb\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      7\u001b[0m     accuracy\u001b[39m.\u001b[39mappend(accuracy_score(prediction, y_test))\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:267\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m    266\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(y\u001b[39m=\u001b[39my)\n\u001b[1;32m--> 267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[0;32m    268\u001b[0m     X, y, np\u001b[39m.\u001b[39;49munique(y), _refit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    269\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:428\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    427\u001b[0m first_call \u001b[39m=\u001b[39m _check_partial_fit_first_call(\u001b[39mself\u001b[39m, classes)\n\u001b[1;32m--> 428\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, reset\u001b[39m=\u001b[39;49mfirst_call)\n\u001b[0;32m    429\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    430\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '?'"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    gnb.fit(X_train, y_train)\n",
    "    prediction = gnb.predict(X_test)\n",
    "    accuracy.append(accuracy_score(prediction, y_test))\n",
    "valid_acc = mean(accuracy)\n",
    "valid_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-fold cross-validtion \n",
    "Validate the accuracy of GNB using 3 fold cross validation technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9533333333333335"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(gnb, X, y, cv=50)\n",
    "mean(cv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-virginica'], dtype='<U15')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gnb = gnb.fit(X.values, y.values) # Warning resoved\n",
    "input = [[4, 1, 2, 3]]\n",
    "model_gnb.predict(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logistic = LogisticRegression(max_iter=10000) # Warning resolved\n",
    "accuracy = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    model_logistic.fit(X_train, y_train)\n",
    "    prediction = model_logistic.predict(X_test)\n",
    "    accuracy.append(accuracy_score(prediction, y_test))\n",
    "valid_acc = mean(accuracy)\n",
    "valid_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: predict **Species** in the **Iris** dataset using Support Vector Machine. \n",
    "*   train the model using 80% and evaluate it based on 20% testset\n",
    "*   apply svm for different kernels\n",
    "*   validate the result in 100 MC runs\n",
    "*   Recommend the type of flower for the first sample in the dataset using the best classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('dataset_CA/StudentsPerformanceEvaluation.csv')\n",
    "X = dataset.drop(['GRADE', 'STUDENT ID'], axis=1)  # Input variables\n",
    "y = dataset['GRADE']  # Output variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm for different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20454545454545456,\n",
       " 0.3409090909090909,\n",
       " 0.22727272727272727,\n",
       " 0.20454545454545456]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)  # testset is 30%\n",
    "    model = SVC(kernel=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, prediction))\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the result of performance for different kernels of svc in 100 MC runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9740000000000002, 0.964, 0.9593333333333333, 0.2515555555555555]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    accuracy_mc = []\n",
    "    for j in range(100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=j)  # testset is 30%\n",
    "        model = SVC(kernel=i, C=1.1)\n",
    "        model.fit(X_train, y_train)\n",
    "        prediction = model.predict(X_test)\n",
    "        accuracy_mc.append(accuracy_score(y_test, prediction))  # append accuracy score in each MC run\n",
    "    accuracy.append(mean(accuracy_mc)) # mean of accuracy and append it in accuracy in kernel array\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-fold cross validation score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9733333333333334,\n",
       " 0.9666666666666668,\n",
       " 0.9733333333333334,\n",
       " 0.06666666666666668]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    model = SVC(kernel=i)\n",
    "    cross_v_score = cross_val_score(model, X, y, scoring='accuracy', cv=10) # cv=10: 10-fold cross validation\n",
    "    # mean of accuracy and append it in accuracy in kernel array\n",
    "    accuracy.append(mean(cross_v_score))\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat the above expriment for NB classifier and logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.98, 0.96, 0.98, 0.16666666666666666],\n",
       " 0.9666666666666667,\n",
       " 0.9533333333333333]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_svc = []\n",
    "accuracy_gnb = []\n",
    "accuracy_lr = []\n",
    "\n",
    "model_lr = LogisticRegression(max_iter=10000)\n",
    "model_gnb = GaussianNB()\n",
    "\n",
    "cross_v_score_lr = cross_val_score(model_lr, X, y, scoring='accuracy', cv=6)\n",
    "cross_v_score_gnb = cross_val_score(gnb, X, y, scoring='accuracy', cv=6)\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    model_svc = SVC(kernel=i)\n",
    "    cross_v_score_svc = cross_val_score(model_svc, X, y, scoring='accuracy', cv=6)\n",
    "    accuracy_svc.append(mean(cross_v_score_svc)) # mean of accuracy and append it in accuracy in kernel array\n",
    "accuracy = [accuracy_svc, mean(cross_v_score_lr), mean(cross_v_score_gnb)]\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Gini index to specify the root node of the decision tree for playtennis dataset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: \n",
    "use decision tree algorithm with gini and entropy rules to predict the species of flowers in the Iris dataset, and compare the result versus SVC and Multinomial logistic regression in 1000 mc runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier # decision tee algorithm for classification\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('dataset/Iris.csv')\n",
    "X = dataset.drop('Species', axis=1)  # matrix of input variables\n",
    "y = dataset['Species']  # output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                 precision    recall  f1-score   support\\n\\n    Iris-setosa       1.00      1.00      1.00        11\\nIris-versicolor       0.89      1.00      0.94         8\\n Iris-virginica       1.00      0.91      0.95        11\\n\\n       accuracy                           0.97        30\\n      macro avg       0.96      0.97      0.96        30\\n   weighted avg       0.97      0.97      0.97        30\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # split dataset\n",
    "model_dt = dt.fit(X_train, y_train)  # fit the model\n",
    "prediction = model_dt.predict(X_test)  # prediction\n",
    "recall = recall_score(y_test, prediction, average='weighted')  # compute recall\n",
    "recall\n",
    "classification_report(y_test, prediction)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_l'] = SVC(kernel='linear')\n",
    "    models['svc_r'] = SVC()\n",
    "    models['svc_s'] = SVC(kernel='sigmoid')\n",
    "    models['svc_p'] = SVC(kernel='poly')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('dataset/Iris.csv')\n",
    "X = dataset.drop('Species', axis=1)  # matrix of input variables\n",
    "y = dataset['Species']  # output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, mc_run, split):\n",
    "    accuracy = [] \n",
    "    for i in range(mc_run):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split)  # split dataset\n",
    "        m = model.fit(X_train, y_train)  # fit the model\n",
    "        prediction = m.predict(X_test)  # prediction\n",
    "        accuracy.append(accuracy_score(y_test, prediction))  # compute & append accuracy\n",
    "        return mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dt_ent', 0.9666666666666667)\n",
      "('dt_gini', 0.9666666666666667)\n",
      "('lr', 0.9666666666666667)\n",
      "('svc_l', 1.0)\n",
      "('svc_r', 0.9333333333333333)\n",
      "('svc_s', 0.2)\n",
      "('svc_p', 1.0)\n"
     ]
    }
   ],
   "source": [
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y, 100, 0.2)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print((name, mean(scores)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the models in dictionary using k-fold cross validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_models defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_l'] = SVC(kernel='linear')\n",
    "    models['svc_r'] = SVC()\n",
    "    models['svc_s'] = SVC(kernel='sigmoid')\n",
    "    models['svc_p'] = SVC(kernel='poly')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_evaluator(model, X, y, k_fold):\n",
    "    scores = cross_val_score(model, X, y, cv=k_fold)\n",
    "    return mean(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following result is the accuracy of different model in the dictionary of SML based on 6-fold cross validation\n",
      "('dt_ent', 0.9533333333333333)\n",
      "('dt_gini', 0.96)\n",
      "('lr', 0.9666666666666667)\n",
      "('svc_l', 0.98)\n",
      "('svc_r', 0.98)\n",
      "('svc_s', 0.16666666666666666)\n",
      "('svc_p', 0.96)\n"
     ]
    }
   ],
   "source": [
    "models = get_models() # Get the model list to be evaluated\n",
    "results, names = list(), list()\n",
    "print('The following result is the accuracy of different model in the dictionary of SML based on 6-fold cross validation')\n",
    "for name, model in models.items():\n",
    "    scores = cross_evaluator(model, X, y, 6)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print((name, mean(scores)))\n",
    "# plot model performance for comparison\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working example for classification:\n",
    "1. create a dictionary of models using svc, logistic regression, GuassianNB and Decision tree with Entropy kernel. \n",
    "2. evaluate the dictionary of models using recall and validate the result in 5-fold cross validation. \n",
    "3. deploy the best model to classify the last sample in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Model Defination\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_l'] = SVC(kernel='linear')\n",
    "    models['svc_r'] = SVC()\n",
    "    models['svc_s'] = SVC(kernel='sigmoid')\n",
    "    models['svc_p'] = SVC(kernel='poly')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocesser\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)  # testset is 10%\n",
    "\n",
    "\n",
    "def data_prep(X_train, X_test, y_train):\n",
    "\n",
    "    # fit and apply the transform\n",
    "    X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
    "    scalar = MinMaxScaler()\n",
    "    N = scalar.fit_transform(X_train_under)\n",
    "    X_strain = DataFrame(N)\n",
    "    header = X_train.columns  # header from the original dataset\n",
    "    X_strain.columns = header\n",
    "    #############################\n",
    "    N = scalar.fit_transform(X_test)\n",
    "    X_stest = DataFrame(N)\n",
    "    header = X.columns  # header from the original dataset\n",
    "    X_stest.columns = header\n",
    "    # undersampler\n",
    "\n",
    "    return X_strain, X_stest, y_train_under\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "1. Define, design, and apply Crisp-DM methodology from Business to Decision.\n",
    "2. Clarify the Business understanding phase in your project.\n",
    "3. Specify the data preparation tasks and elaborate on their needs in your project.\n",
    "4. Apply three Machine learning models. Elaborate on the mathematical requirements and explain each model.\n",
    "5. Evaluate and validate the models using an appropriate measure of performance.\n",
    "6. Deploy the best model and elaborate on the insights and findings of your projec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from statsmodels.api import GLM, add_constant, families\n",
    "from sklearn.svm import SVC\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loding and Identifying Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    508\n",
       "0    410\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_csv('dataset_CA/heart2.csv')\n",
    "X = data.drop('HeartDisease', axis=1)  # input\n",
    "y = data['HeartDisease']   # output\n",
    "y.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(X):\n",
    "    OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    data_sex_OHE = OHE.fit_transform(X[['Sex']])\n",
    "    data_sex_DF = DataFrame(data_sex_OHE.toarray())\n",
    "    data_sex_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ChestPainType_OHE = OHE.fit_transform(X[['ChestPainType']])\n",
    "    data_ChestPainType_DF = DataFrame(data_ChestPainType_OHE.toarray())\n",
    "    data_ChestPainType_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_RestingECG_OHE = OHE.fit_transform(X[['RestingECG']])\n",
    "    data_RestingECG_DF = DataFrame(data_RestingECG_OHE.toarray())\n",
    "    data_RestingECG_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ExerciseAngina_OHE = OHE.fit_transform(X[['ExerciseAngina']])\n",
    "    data_ExerciseAngina_DF = DataFrame(data_ExerciseAngina_OHE.toarray())\n",
    "    data_ExerciseAngina_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ST_Slope_OHE = OHE.fit_transform(X[['ST_Slope']])\n",
    "    data_ST_Slope_DF = DataFrame(data_ST_Slope_OHE.toarray())\n",
    "    data_ST_Slope_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    #***********************Merging multiple DataFrames***********************\n",
    "\n",
    "    X_binary = concat([data_sex_DF, data_ChestPainType_DF, data_RestingECG_DF, data_ExerciseAngina_DF, data_ST_Slope_DF, X[['FastingBS']]], axis=1)\n",
    "    X_scalable = X[['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']]  # Orginal numeric columns\n",
    "\n",
    "    #***********************Applying StandardScaler***********************\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(X_scalable)\n",
    "    X_scaled_DF = DataFrame(X_scaled)\n",
    "    X_scaled_DF.columns = X_scalable.columns\n",
    "\n",
    "    #***********************Applying MinMaxScaler***********************\n",
    "\n",
    "    # X_scaled = MinMaxScaler().fit_transform(X_scalable)\n",
    "    # X_scaled_DF = DataFrame(X_scaled)\n",
    "    # X_scaled_DF.columns = X_scalable.columns\n",
    "\n",
    "    X_PREP = concat([X_scalable, X_binary], axis=1)  # Prepared Data\n",
    "\n",
    "    X = add_constant(X_PREP)  # Add Intercept\n",
    "\n",
    "    # X = X_PREP\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_prep(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # 80% training and 20% test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_models() Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_linear'] = SVC(kernel='linear')\n",
    "    models['svc_rbf'] = SVC()\n",
    "    models['svc_sigmoid'] = SVC(kernel='sigmoid')\n",
    "    models['svc_poly'] = SVC(kernel='poly')\n",
    "    return models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation using Monte Calro sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_mc(model, X, y, mc, split):\n",
    "    accuracy = [] \n",
    "    for i in range(mc):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=i)  # split dataset\n",
    "        m = model.fit(X_train, y_train)  # fit the model\n",
    "        prediction = m.predict(X_test)  # prediction\n",
    "        accuracy.append(accuracy_score(y_test, prediction))  # compute & append accuracy\n",
    "        return mean(accuracy)\n",
    "    \n",
    "def model_score_mc(X, y, mc, split): # Evaluate the models and store results\n",
    "    models = get_models()\n",
    "    score = dict()\n",
    "    for name, model in models.items():\n",
    "        scores = evaluate_model_mc(model, X, y, mc, split)\n",
    "        score[name] = scores\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_score_mc(X, y, 100, 0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: SVM with linear kernel provides us the best classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SVC(kernel='linear')\n",
    "best.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = X.tail(1)\n",
    "prediction = best_model.predict(input)\n",
    "print('Prediction', prediction)\n",
    "y.tail(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation based on k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_evaluator(model, X, y, k_fold):\n",
    "    scores = cross_val_score(model, X, y, cv=k_fold)\n",
    "    return mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8695652173913043, 0.8695652173913043]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gnb = GaussianNB().fit(X_train, y_train) # Train the model using the training sets\n",
    "\n",
    "prediction = gnb.predict(X_test)  # Predict the response for test dataset\n",
    "df = DataFrame({'Prediction': prediction, \"Actual\": y_test})\n",
    "df\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction, average='micro')\n",
    "[accuracy, recall]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

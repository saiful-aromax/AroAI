{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "1. Define, design, and apply Crisp-DM methodology from Business to Decision.\n",
    "2. Clarify the Business understanding phase in your project.\n",
    "3. Specify the data preparation tasks and elaborate on their needs in your project.\n",
    "4. Apply three Machine learning models. Elaborate on the mathematical requirements and explain each model.\n",
    "5. Evaluate and validate the models using an appropriate measure of performance.\n",
    "6. Deploy the best model and elaborate on the insights and findings of your projec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from statsmodels.api import GLM, add_constant, families\n",
    "from sklearn.svm import SVC\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loding and Identifying Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    508\n",
       "0    410\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_csv('dataset_CA/heart2.csv')\n",
    "X = data.drop('HeartDisease', axis=1)  # input\n",
    "y = data['HeartDisease']   # output\n",
    "y.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(X):\n",
    "    OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    data_sex_OHE = OHE.fit_transform(X[['Sex']])\n",
    "    data_sex_DF = DataFrame(data_sex_OHE.toarray())\n",
    "    data_sex_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ChestPainType_OHE = OHE.fit_transform(X[['ChestPainType']])\n",
    "    data_ChestPainType_DF = DataFrame(data_ChestPainType_OHE.toarray())\n",
    "    data_ChestPainType_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_RestingECG_OHE = OHE.fit_transform(X[['RestingECG']])\n",
    "    data_RestingECG_DF = DataFrame(data_RestingECG_OHE.toarray())\n",
    "    data_RestingECG_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ExerciseAngina_OHE = OHE.fit_transform(X[['ExerciseAngina']])\n",
    "    data_ExerciseAngina_DF = DataFrame(data_ExerciseAngina_OHE.toarray())\n",
    "    data_ExerciseAngina_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ST_Slope_OHE = OHE.fit_transform(X[['ST_Slope']])\n",
    "    data_ST_Slope_DF = DataFrame(data_ST_Slope_OHE.toarray())\n",
    "    data_ST_Slope_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    #***********************Merging multiple DataFrames***********************\n",
    "\n",
    "    X_binary = concat([data_sex_DF, data_ChestPainType_DF, data_RestingECG_DF, data_ExerciseAngina_DF, data_ST_Slope_DF, X[['FastingBS']]], axis=1)\n",
    "    X_scalable = X[['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']]  # Orginal numeric columns\n",
    "\n",
    "    #***********************Applying StandardScaler***********************\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(X_scalable)\n",
    "    X_scaled_DF = DataFrame(X_scaled)\n",
    "    X_scaled_DF.columns = X_scalable.columns\n",
    "\n",
    "    #***********************Applying MinMaxScaler***********************\n",
    "\n",
    "    # X_scaled = MinMaxScaler().fit_transform(X_scalable)\n",
    "    # X_scaled_DF = DataFrame(X_scaled)\n",
    "    # X_scaled_DF.columns = X_scalable.columns\n",
    "\n",
    "    X_PREP = concat([X_scalable, X_binary], axis=1)  # Prepared Data\n",
    "\n",
    "    X = add_constant(X_PREP)  # Add Intercept\n",
    "\n",
    "    # X = X_PREP\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_prep(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # 80% training and 20% test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_models() Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_l'] = SVC(kernel='linear')\n",
    "    models['svc_r'] = SVC()\n",
    "    models['svc_s'] = SVC(kernel='sigmoid')\n",
    "    models['svc_p'] = SVC(kernel='poly')\n",
    "    return models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation using Monte Calro sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_mc(model, X, y, mc, split):\n",
    "    accuracy = [] \n",
    "    for i in range(mc):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split)  # split dataset\n",
    "        m = model.fit(X_train, y_train)  # fit the model\n",
    "        prediction = m.predict(X_test)  # prediction\n",
    "        accuracy.append(accuracy_score(y_test, prediction))  # compute & append accuracy\n",
    "        return mean(accuracy)\n",
    "    \n",
    "def model_score_mc(file_url, y_value, mc, split):\n",
    "    dataset = read_csv(file_url)\n",
    "    X = dataset.drop(y_value, axis=1)  # matrix of input variables\n",
    "    y = dataset[y_value]  # output variable\n",
    "    models = get_models()\n",
    "    # evaluate the models and store results\n",
    "    results, names = list(), list()\n",
    "    output = dict()\n",
    "    for name, model in models.items():\n",
    "        scores = evaluate_model_mc(model, X, y, mc, split)\n",
    "        output[name] = scores\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation based on k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_evaluator(model, X, y, k_fold):\n",
    "    scores = cross_val_score(model, X, y, cv=k_fold)\n",
    "    return mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8695652173913043, 0.8695652173913043]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gnb = GaussianNB().fit(X_train, y_train) # Train the model using the training sets\n",
    "\n",
    "prediction = gnb.predict(X_test)  # Predict the response for test dataset\n",
    "df = DataFrame({'Prediction': prediction, \"Actual\": y_test})\n",
    "df\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction, average='micro')\n",
    "[accuracy, recall]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation using Monte Calro sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8559782608695653"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "for r in range(1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    gnb = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "    prediction = gnb.predict(X_test)  # Predict the response for test dataset\n",
    "    accuracy.append(accuracy_score(y_test, prediction))\n",
    "mean(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation based on Cross Validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835511982570806"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "scores = cross_val_score(gnb, X, y, cv=2)\n",
    "mean(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction: for the last sample in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "917    0\n",
      "Name: HeartDisease, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input = X.tail(1)\n",
    "gnb.fit(X, y)\n",
    "print(y.tail(1))\n",
    "gnb.predict(X_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Use iris dataset\n",
    "1.  Fit the Naive Bayes classifier  and evaluate the accuracy of the model in 100 mc runs. use 80% as the trainset and 20% testset.\n",
    "2.  Recommend the type of flower for the following sample: X=[4,1,2,3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('dataset_CA/c2k_data_comma.csv')\n",
    "X = data.drop('legs', axis=1)  # input\n",
    "y = data['legs']   # output\n",
    "# y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '?'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[0;32m      4\u001b[0m     X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39mi)\n\u001b[1;32m----> 5\u001b[0m     gnb\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      6\u001b[0m     prediction \u001b[39m=\u001b[39m gnb\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      7\u001b[0m     accuracy\u001b[39m.\u001b[39mappend(accuracy_score(prediction, y_test))\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:267\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m    266\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(y\u001b[39m=\u001b[39my)\n\u001b[1;32m--> 267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[0;32m    268\u001b[0m     X, y, np\u001b[39m.\u001b[39;49munique(y), _refit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    269\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:428\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    427\u001b[0m first_call \u001b[39m=\u001b[39m _check_partial_fit_first_call(\u001b[39mself\u001b[39m, classes)\n\u001b[1;32m--> 428\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, reset\u001b[39m=\u001b[39;49mfirst_call)\n\u001b[0;32m    429\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    430\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aromax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '?'"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    gnb.fit(X_train, y_train)\n",
    "    prediction = gnb.predict(X_test)\n",
    "    accuracy.append(accuracy_score(prediction, y_test))\n",
    "valid_acc = mean(accuracy)\n",
    "valid_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-fold cross-validtion \n",
    "Validate the accuracy of GNB using 3 fold cross validation technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9533333333333335"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(gnb, X, y, cv=50)\n",
    "mean(cv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-virginica'], dtype='<U15')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gnb = gnb.fit(X.values, y.values) # Warning resoved\n",
    "input = [[4, 1, 2, 3]]\n",
    "model_gnb.predict(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logistic = LogisticRegression(max_iter=10000) # Warning resolved\n",
    "accuracy = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    model_logistic.fit(X_train, y_train)\n",
    "    prediction = model_logistic.predict(X_test)\n",
    "    accuracy.append(accuracy_score(prediction, y_test))\n",
    "valid_acc = mean(accuracy)\n",
    "valid_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: predict **Species** in the **Iris** dataset using Support Vector Machine. \n",
    "*   train the model using 80% and evaluate it based on 20% testset\n",
    "*   apply svm for different kernels\n",
    "*   validate the result in 100 MC runs\n",
    "*   Recommend the type of flower for the first sample in the dataset using the best classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('dataset_CA/StudentsPerformanceEvaluation.csv')\n",
    "X = dataset.drop(['GRADE', 'STUDENT ID'], axis=1)  # Input variables\n",
    "y = dataset['GRADE']  # Output variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm for different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20454545454545456,\n",
       " 0.3409090909090909,\n",
       " 0.22727272727272727,\n",
       " 0.20454545454545456]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)  # testset is 30%\n",
    "    model = SVC(kernel=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, prediction))\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the result of performance for different kernels of svc in 100 MC runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9740000000000002, 0.964, 0.9593333333333333, 0.2515555555555555]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    accuracy_mc = []\n",
    "    for j in range(100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=j)  # testset is 30%\n",
    "        model = SVC(kernel=i, C=1.1)\n",
    "        model.fit(X_train, y_train)\n",
    "        prediction = model.predict(X_test)\n",
    "        accuracy_mc.append(accuracy_score(y_test, prediction))  # append accuracy score in each MC run\n",
    "    accuracy.append(mean(accuracy_mc)) # mean of accuracy and append it in accuracy in kernel array\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-fold cross validation score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9733333333333334,\n",
       " 0.9666666666666668,\n",
       " 0.9733333333333334,\n",
       " 0.06666666666666668]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    model = SVC(kernel=i)\n",
    "    cross_v_score = cross_val_score(model, X, y, scoring='accuracy', cv=10) # cv=10: 10-fold cross validation\n",
    "    # mean of accuracy and append it in accuracy in kernel array\n",
    "    accuracy.append(mean(cross_v_score))\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat the above expriment for NB classifier and logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.98, 0.96, 0.98, 0.16666666666666666],\n",
       " 0.9666666666666667,\n",
       " 0.9533333333333333]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_svc = []\n",
    "accuracy_gnb = []\n",
    "accuracy_lr = []\n",
    "\n",
    "model_lr = LogisticRegression(max_iter=10000)\n",
    "model_gnb = GaussianNB()\n",
    "\n",
    "cross_v_score_lr = cross_val_score(model_lr, X, y, scoring='accuracy', cv=6)\n",
    "cross_v_score_gnb = cross_val_score(gnb, X, y, scoring='accuracy', cv=6)\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    model_svc = SVC(kernel=i)\n",
    "    cross_v_score_svc = cross_val_score(model_svc, X, y, scoring='accuracy', cv=6)\n",
    "    accuracy_svc.append(mean(cross_v_score_svc)) # mean of accuracy and append it in accuracy in kernel array\n",
    "accuracy = [accuracy_svc, mean(cross_v_score_lr), mean(cross_v_score_gnb)]\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Gini index to specify the root node of the decision tree for playtennis dataset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: \n",
    "use decision tree algorithm with gini and entropy rules to predict the species of flowers in the Iris dataset, and compare the result versus SVC and Multinomial logistic regression in 1000 mc runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier # decision tee algorithm for classification\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('dataset/Iris.csv')\n",
    "X = dataset.drop('Species', axis=1)  # matrix of input variables\n",
    "y = dataset['Species']  # output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                 precision    recall  f1-score   support\\n\\n    Iris-setosa       1.00      1.00      1.00        11\\nIris-versicolor       0.89      1.00      0.94         8\\n Iris-virginica       1.00      0.91      0.95        11\\n\\n       accuracy                           0.97        30\\n      macro avg       0.96      0.97      0.96        30\\n   weighted avg       0.97      0.97      0.97        30\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # split dataset\n",
    "model_dt = dt.fit(X_train, y_train)  # fit the model\n",
    "prediction = model_dt.predict(X_test)  # prediction\n",
    "recall = recall_score(y_test, prediction, average='weighted')  # compute recall\n",
    "recall\n",
    "classification_report(y_test, prediction)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_l'] = SVC(kernel='linear')\n",
    "    models['svc_r'] = SVC()\n",
    "    models['svc_s'] = SVC(kernel='sigmoid')\n",
    "    models['svc_p'] = SVC(kernel='poly')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('dataset/Iris.csv')\n",
    "X = dataset.drop('Species', axis=1)  # matrix of input variables\n",
    "y = dataset['Species']  # output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, mc_run, split):\n",
    "    accuracy = [] \n",
    "    for i in range(mc_run):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split)  # split dataset\n",
    "        m = model.fit(X_train, y_train)  # fit the model\n",
    "        prediction = m.predict(X_test)  # prediction\n",
    "        accuracy.append(accuracy_score(y_test, prediction))  # compute & append accuracy\n",
    "        return mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dt_ent', 0.9666666666666667)\n",
      "('dt_gini', 0.9666666666666667)\n",
      "('lr', 0.9666666666666667)\n",
      "('svc_l', 1.0)\n",
      "('svc_r', 0.9333333333333333)\n",
      "('svc_s', 0.2)\n",
      "('svc_p', 1.0)\n"
     ]
    }
   ],
   "source": [
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y, 100, 0.2)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print((name, mean(scores)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the models in dictionary using k-fold cross validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_models defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_l'] = SVC(kernel='linear')\n",
    "    models['svc_r'] = SVC()\n",
    "    models['svc_s'] = SVC(kernel='sigmoid')\n",
    "    models['svc_p'] = SVC(kernel='poly')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_evaluator(model, X, y, k_fold):\n",
    "    scores = cross_val_score(model, X, y, cv=k_fold)\n",
    "    return mean(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following result is the accuracy of different model in the dictionary of SML based on 6-fold cross validation\n",
      "('dt_ent', 0.9533333333333333)\n",
      "('dt_gini', 0.96)\n",
      "('lr', 0.9666666666666667)\n",
      "('svc_l', 0.98)\n",
      "('svc_r', 0.98)\n",
      "('svc_s', 0.16666666666666666)\n",
      "('svc_p', 0.96)\n"
     ]
    }
   ],
   "source": [
    "models = get_models() # Get the model list to be evaluated\n",
    "results, names = list(), list()\n",
    "print('The following result is the accuracy of different model in the dictionary of SML based on 6-fold cross validation')\n",
    "for name, model in models.items():\n",
    "    scores = cross_evaluator(model, X, y, 6)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print((name, mean(scores)))\n",
    "# plot model performance for comparison\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working example for classification:\n",
    "1. create a dictionary of models using svc, logistic regression, GuassianNB and Decision tree with Entropy kernel. \n",
    "2. evaluate the dictionary of models using recall and validate the result in 5-fold cross validation. \n",
    "3. deploy the best model to classify the last sample in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Model Defination\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_l'] = SVC(kernel='linear')\n",
    "    models['svc_r'] = SVC()\n",
    "    models['svc_s'] = SVC(kernel='sigmoid')\n",
    "    models['svc_p'] = SVC(kernel='poly')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocesser\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)  # testset is 10%\n",
    "\n",
    "\n",
    "def data_prep(X_train, X_test, y_train):\n",
    "\n",
    "    # fit and apply the transform\n",
    "    X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
    "    scalar = MinMaxScaler()\n",
    "    N = scalar.fit_transform(X_train_under)\n",
    "    X_strain = DataFrame(N)\n",
    "    header = X_train.columns  # header from the original dataset\n",
    "    X_strain.columns = header\n",
    "    #############################\n",
    "    N = scalar.fit_transform(X_test)\n",
    "    X_stest = DataFrame(N)\n",
    "    header = X.columns  # header from the original dataset\n",
    "    X_stest.columns = header\n",
    "    # undersampler\n",
    "\n",
    "    return X_strain, X_stest, y_train_under\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

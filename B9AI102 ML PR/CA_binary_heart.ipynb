{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "1. Define, design, and apply Crisp-DM methodology from Business to Decision.\n",
    "2. Clarify the Business understanding phase in your project.\n",
    "3. Specify the data preparation tasks and elaborate on their needs in your project.\n",
    "4. Apply three Machine learning models. Elaborate on the mathematical requirements and explain each model.\n",
    "5. Evaluate and validate the models using an appropriate measure of performance.\n",
    "6. Deploy the best model and elaborate on the insights and findings of your projec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from statsmodels.api import GLM, add_constant, families\n",
    "from sklearn.svm import SVC\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loding and Identifying Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    508\n",
       "0    410\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_csv('dataset_CA/heart2.csv')\n",
    "X = data.drop('HeartDisease', axis=1)  # input\n",
    "y = data['HeartDisease']   # output\n",
    "y.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(X):\n",
    "    OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    data_sex_OHE = OHE.fit_transform(X[['Sex']])\n",
    "    data_sex_DF = DataFrame(data_sex_OHE.toarray())\n",
    "    data_sex_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ChestPainType_OHE = OHE.fit_transform(X[['ChestPainType']])\n",
    "    data_ChestPainType_DF = DataFrame(data_ChestPainType_OHE.toarray())\n",
    "    data_ChestPainType_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_RestingECG_OHE = OHE.fit_transform(X[['RestingECG']])\n",
    "    data_RestingECG_DF = DataFrame(data_RestingECG_OHE.toarray())\n",
    "    data_RestingECG_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ExerciseAngina_OHE = OHE.fit_transform(X[['ExerciseAngina']])\n",
    "    data_ExerciseAngina_DF = DataFrame(data_ExerciseAngina_OHE.toarray())\n",
    "    data_ExerciseAngina_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ST_Slope_OHE = OHE.fit_transform(X[['ST_Slope']])\n",
    "    data_ST_Slope_DF = DataFrame(data_ST_Slope_OHE.toarray())\n",
    "    data_ST_Slope_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    #***********************Merging multiple DataFrames***********************\n",
    "\n",
    "    X_binary = concat([data_sex_DF, data_ChestPainType_DF, data_RestingECG_DF, data_ExerciseAngina_DF, data_ST_Slope_DF, X[['FastingBS']]], axis=1)\n",
    "    X_scalable = X[['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']]  # Orginal numeric columns\n",
    "\n",
    "    #***********************Applying StandardScaler***********************\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(X_scalable)\n",
    "    X_scaled_DF = DataFrame(X_scaled)\n",
    "    X_scaled_DF.columns = X_scalable.columns\n",
    "\n",
    "    #***********************Applying MinMaxScaler***********************\n",
    "\n",
    "    # X_scaled = MinMaxScaler().fit_transform(X_scalable)\n",
    "    # X_scaled_DF = DataFrame(X_scaled)\n",
    "    # X_scaled_DF.columns = X_scalable.columns\n",
    "\n",
    "    X_PREP = concat([X_scalable, X_binary], axis=1)  # Prepared Data\n",
    "\n",
    "    X = add_constant(X_PREP)  # Add Intercept\n",
    "\n",
    "    # X = X_PREP\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_prep(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # 80% training and 20% test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_models() Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    \n",
    "    #***********************Base Classifier***********************\n",
    "    \n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_linear'] = SVC(kernel='linear')\n",
    "    models['svc_rbf'] = SVC()\n",
    "    models['svc_sigmoid'] = SVC(kernel='sigmoid')\n",
    "    models['svc_poly'] = SVC(kernel='poly')\n",
    "    \n",
    "    # #***********************Bagging Classifier***********************\n",
    "\n",
    "    # models['bag_dt_ent'] = BaggingClassifier(estimator=models['dt_ent'], n_estimators=50, max_samples=0.8, max_features=0.8)\n",
    "    # models['bag_dt_gini'] = BaggingClassifier(estimator=models['dt_gini'], n_estimators=50, max_samples=0.8, max_features=0.8)\n",
    "    # models['bag_lr'] = BaggingClassifier(estimator=models['lr'], n_estimators=50, max_samples=0.8, max_features=0.8)\n",
    "    # models['bag_svc_linear'] = BaggingClassifier(estimator=models['svc_linear'], n_estimators=50, max_samples=0.8, max_features=0.8)\n",
    "    # models['bag_svc_rbf'] = BaggingClassifier(estimator=models['svc_rbf'], n_estimators=50, max_samples=0.8, max_features=0.8)\n",
    "    # models['bag_svc_sigmoid'] = BaggingClassifier(estimator=models['svc_sigmoid'], n_estimators=50, max_samples=0.8, max_features=0.8)\n",
    "    # models['bag_svc_poly'] = BaggingClassifier(estimator=models['svc_poly'], n_estimators=50, max_samples=0.8, max_features=0.8)\n",
    "    return models\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation using Monte Calro sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_by_model(model, X, y, mc, split):\n",
    "    accuracy = []\n",
    "    for i in range(mc):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=i)  # split dataset\n",
    "        m = model.fit(X_train, y_train)  # fit the model\n",
    "        prediction = m.predict(X_test)  # prediction\n",
    "        # compute & append accuracy\n",
    "        accuracy.append(accuracy_score(y_test, prediction))\n",
    "        return mean(accuracy)\n",
    "\n",
    "\n",
    "# Evaluate models by score\n",
    "def evaluate_accuracy_score(X, y, mc, split):\n",
    "    models = get_models()\n",
    "    score = dict()\n",
    "    for name, model in models.items():\n",
    "        scores = accuracy_score_by_model(model, X, y, mc, split)\n",
    "        score[name] = scores\n",
    "    return score\n",
    "\n",
    "def recall_score_by_model(model, X, y, mc, split):\n",
    "    accuracy = []\n",
    "    for i in range(mc):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=i)  # split dataset\n",
    "        m = model.fit(X_train, y_train)  # fit the model\n",
    "        prediction = m.predict(X_test)  # prediction\n",
    "        # compute & append recall\n",
    "        accuracy.append(accuracy_score(y_test, prediction))\n",
    "        return mean(accuracy)\n",
    "\n",
    "# Evaluate models by recall\n",
    "def evaluate_recall_score(X, y, mc, split):\n",
    "    models = get_models()\n",
    "    score = dict()\n",
    "    for name, model in models.items():\n",
    "        scores = recall_score_by_model(model, X, y, mc, split)\n",
    "        score[name] = scores\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = evaluate_recall_score(X, y, 100, 0.2)\n",
    "print('*********Recall*********')\n",
    "for item in recall:\n",
    "  print(item, recall[item])\n",
    "print('*********Accuracy*********')\n",
    "accuracy = evaluate_accuracy_score(X, y, 100, 0.2)\n",
    "for item in accuracy:\n",
    "  print(item, accuracy[item])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: SVM with linear kernel provides us the best classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'), n_estimators=50, max_samples=0.8, max_features=0.8)\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = X.tail(1)\n",
    "prediction = best_model.predict(input)\n",
    "print('Prediction', prediction)\n",
    "y.tail(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation based on k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_evaluator(model, X, y, k_fold):\n",
    "    scores = cross_val_score(model, X, y, cv=k_fold)\n",
    "    return mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8695652173913043, 0.8695652173913043]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gnb = GaussianNB().fit(X_train, y_train) # Train the model using the training sets\n",
    "\n",
    "prediction = gnb.predict(X_test)  # Predict the response for test dataset\n",
    "df = DataFrame({'Prediction': prediction, \"Actual\": y_test})\n",
    "df\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction, average='micro')\n",
    "[accuracy, recall]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

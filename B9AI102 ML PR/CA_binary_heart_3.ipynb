{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "1. Define, design, and apply Crisp-DM methodology from Business to Decision.\n",
    "2. Clarify the Business understanding phase in your project.\n",
    "3. Specify the data preparation tasks and elaborate on their needs in your project.\n",
    "4. Apply three Machine learning models. Elaborate on the mathematical requirements and explain each model.\n",
    "5. Evaluate and validate the models using an appropriate measure of performance.\n",
    "6. Deploy the best model and elaborate on the insights and findings of your projec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from statsmodels.api import GLM, add_constant, families\n",
    "from sklearn.svm import SVC\n",
    "from numpy import mean, std\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loding and Identifying Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    508\n",
      "0    410\n",
      "Name: HeartDisease, dtype: int64\n",
      "Counter({0: 508, 1: 508})\n"
     ]
    }
   ],
   "source": [
    "data = read_csv('dataset_CA/heart2.csv')\n",
    "X = data.drop('HeartDisease', axis=1)  # input\n",
    "y = data['HeartDisease']   # output\n",
    "print(y.value_counts())\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(X_over):\n",
    "    OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    data_sex_OHE = OHE.fit_transform(X_over[['Sex']])\n",
    "    data_sex_DF = DataFrame(data_sex_OHE.toarray())\n",
    "    data_sex_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ChestPainType_OHE = OHE.fit_transform(X_over[['ChestPainType']])\n",
    "    data_ChestPainType_DF = DataFrame(data_ChestPainType_OHE.toarray())\n",
    "    data_ChestPainType_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_RestingECG_OHE = OHE.fit_transform(X_over[['RestingECG']])\n",
    "    data_RestingECG_DF = DataFrame(data_RestingECG_OHE.toarray())\n",
    "    data_RestingECG_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ExerciseAngina_OHE = OHE.fit_transform(X_over[['ExerciseAngina']])\n",
    "    data_ExerciseAngina_DF = DataFrame(data_ExerciseAngina_OHE.toarray())\n",
    "    data_ExerciseAngina_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ST_Slope_OHE = OHE.fit_transform(X_over[['ST_Slope']])\n",
    "    data_ST_Slope_DF = DataFrame(data_ST_Slope_OHE.toarray())\n",
    "    data_ST_Slope_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    #***********************Merging multiple DataFrames***********************\n",
    "\n",
    "    X_binary = concat([data_sex_DF, data_ChestPainType_DF, data_RestingECG_DF, data_ExerciseAngina_DF, data_ST_Slope_DF, X_over[['FastingBS']]], axis=1)\n",
    "    X_scalable = X_over[['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']]  # Orginal numeric columns\n",
    "\n",
    "    #***********************Applying StandardScaler***********************\n",
    "\n",
    "    # X_scaled = StandardScaler().fit_transform(X_scalable)\n",
    "    # X_scaled_DF = DataFrame(X_scaled)\n",
    "    # X_scaled_DF.columns = X_scalable.columns\n",
    "\n",
    "    #***********************Applying MinMaxScaler***********************\n",
    "\n",
    "    X_scaled = MinMaxScaler().fit_transform(X_scalable)\n",
    "    X_scaled_DF = DataFrame(X_scaled)\n",
    "    X_scaled_DF.columns = X_scalable.columns\n",
    "\n",
    "    X_PREP = concat([X_scalable, X_binary], axis=1)  # Prepared Data\n",
    "\n",
    "    X_over = add_constant(X_PREP)  # Add Intercept\n",
    "\n",
    "    # X = X_PREP\n",
    "    return X_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over = data_prep(X_over)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # 80% training and 20% test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_base_models() Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_models():\n",
    "    models = dict()\n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_linear'] = SVC(kernel='linear')\n",
    "    models['svc_rbf'] = SVC()\n",
    "    models['svc_sigmoid'] = SVC(kernel='sigmoid')\n",
    "    models['svc_poly'] = SVC(kernel='poly')\n",
    "    return models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation based on k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********Cross Validation Score for each Model*********\n",
      ">Model: dt_ent, Mean Score: 0.809, Standard Deviation: 0.019\n",
      ">Model: lr, Mean Score: 0.821, Standard Deviation: 0.037\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models by cross validation score\n",
    "def evaluate_model_by_cv(X_over, y_over):\n",
    "    models = get_base_models()\n",
    "    score = dict()\n",
    "    for name, model in models.items():\n",
    "        scores = cross_val_score(model, X_over, y_over, scoring=\"recall_weighted\")\n",
    "        score[name] = scores\n",
    "    return score\n",
    "\n",
    "score = evaluate_model_by_cv(X_over, y_over)\n",
    "print('*********Cross Validation Score for each Model*********')\n",
    "for item in score:\n",
    "    print('>Model: %s, Mean Score: %.3f, Standard Deviation: %.3f' % (item, mean(score[item]), std(score[item])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: SVM with linear kernel provides us the best classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'), n_estimators=50, max_samples=0.8, max_features=0.8)\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = X.tail(1)\n",
    "prediction = best_model.predict(input)\n",
    "print('Prediction', prediction)\n",
    "y.tail(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

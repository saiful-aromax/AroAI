{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "1. Define, design, and apply Crisp-DM methodology from Business to Decision.\n",
    "2. Clarify the Business understanding phase in your project.\n",
    "3. Specify the data preparation tasks and elaborate on their needs in your project.\n",
    "4. Apply three Machine learning models. Elaborate on the mathematical requirements and explain each model.\n",
    "5. Evaluate and validate the models using an appropriate measure of performance.\n",
    "6. Deploy the best model and elaborate on the insights and findings of your projec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from statsmodels.api import GLM, add_constant, families\n",
    "from sklearn.svm import SVC\n",
    "from numpy import mean, std\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, StackingClassifier  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loding and Identifying Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    508\n",
      "0    410\n",
      "Name: HeartDisease, dtype: int64\n",
      "Counter({0: 508, 1: 508})\n"
     ]
    }
   ],
   "source": [
    "data = read_csv('dataset_CA/heart2.csv')\n",
    "X = data.drop('HeartDisease', axis=1)  # input\n",
    "y = data['HeartDisease']   # output\n",
    "print(y.value_counts())\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(X_over):\n",
    "    OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    data_sex_OHE = OHE.fit_transform(X_over[['Sex']])\n",
    "    data_sex_DF = DataFrame(data_sex_OHE.toarray())\n",
    "    data_sex_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ChestPainType_OHE = OHE.fit_transform(X_over[['ChestPainType']])\n",
    "    data_ChestPainType_DF = DataFrame(data_ChestPainType_OHE.toarray())\n",
    "    data_ChestPainType_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_RestingECG_OHE = OHE.fit_transform(X_over[['RestingECG']])\n",
    "    data_RestingECG_DF = DataFrame(data_RestingECG_OHE.toarray())\n",
    "    data_RestingECG_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ExerciseAngina_OHE = OHE.fit_transform(X_over[['ExerciseAngina']])\n",
    "    data_ExerciseAngina_DF = DataFrame(data_ExerciseAngina_OHE.toarray())\n",
    "    data_ExerciseAngina_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    data_ST_Slope_OHE = OHE.fit_transform(X_over[['ST_Slope']])\n",
    "    data_ST_Slope_DF = DataFrame(data_ST_Slope_OHE.toarray())\n",
    "    data_ST_Slope_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "    #***********************Merging multiple DataFrames***********************\n",
    "\n",
    "    X_binary = concat([data_sex_DF, data_ChestPainType_DF, data_RestingECG_DF, data_ExerciseAngina_DF, data_ST_Slope_DF, X_over[['FastingBS']]], axis=1)\n",
    "    X_scalable = X_over[['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']]  # Orginal numeric columns\n",
    "\n",
    "    #***********************Applying StandardScaler***********************\n",
    "\n",
    "    # X_scaled = StandardScaler().fit_transform(X_scalable)\n",
    "    # X_scaled_DF = DataFrame(X_scaled)\n",
    "    # X_scaled_DF.columns = X_scalable.columns\n",
    "\n",
    "    #***********************Applying MinMaxScaler***********************\n",
    "\n",
    "    X_scaled = MinMaxScaler().fit_transform(X_scalable)\n",
    "    X_scaled_DF = DataFrame(X_scaled)\n",
    "    X_scaled_DF.columns = X_scalable.columns\n",
    "\n",
    "    X_PREP = concat([X_scalable, X_binary], axis=1)  # Prepared Data\n",
    "\n",
    "    X_over = add_constant(X_PREP)  # Add Intercept\n",
    "\n",
    "    # X = X_PREP\n",
    "    return X_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>ChestPainType_ASY</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>...</th>\n",
       "      <th>ChestPainType_TA</th>\n",
       "      <th>RestingECG_LVH</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>RestingECG_ST</th>\n",
       "      <th>ExerciseAngina_N</th>\n",
       "      <th>ExerciseAngina_Y</th>\n",
       "      <th>ST_Slope_Down</th>\n",
       "      <th>ST_Slope_Flat</th>\n",
       "      <th>ST_Slope_Up</th>\n",
       "      <th>FastingBS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>108</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   const  Age  RestingBP  Cholesterol  MaxHR  Oldpeak  Sex_F  Sex_M  \\\n",
       "0    1.0   40        140          289    172      0.0    0.0    1.0   \n",
       "1    1.0   49        160          180    156      1.0    1.0    0.0   \n",
       "2    1.0   37        130          283     98      0.0    0.0    1.0   \n",
       "3    1.0   48        138          214    108      1.5    1.0    0.0   \n",
       "4    1.0   54        150          195    122      0.0    0.0    1.0   \n",
       "\n",
       "   ChestPainType_ASY  ChestPainType_ATA  ...  ChestPainType_TA  \\\n",
       "0                0.0                1.0  ...               0.0   \n",
       "1                0.0                0.0  ...               0.0   \n",
       "2                0.0                1.0  ...               0.0   \n",
       "3                1.0                0.0  ...               0.0   \n",
       "4                0.0                0.0  ...               0.0   \n",
       "\n",
       "   RestingECG_LVH  RestingECG_Normal  RestingECG_ST  ExerciseAngina_N  \\\n",
       "0             0.0                1.0            0.0               1.0   \n",
       "1             0.0                1.0            0.0               1.0   \n",
       "2             0.0                0.0            1.0               1.0   \n",
       "3             0.0                1.0            0.0               0.0   \n",
       "4             0.0                1.0            0.0               1.0   \n",
       "\n",
       "   ExerciseAngina_Y  ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up  FastingBS  \n",
       "0               0.0            0.0            0.0          1.0          0  \n",
       "1               0.0            0.0            1.0          0.0          0  \n",
       "2               0.0            0.0            0.0          1.0          0  \n",
       "3               1.0            0.0            1.0          0.0          0  \n",
       "4               0.0            0.0            0.0          1.0          0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over = data_prep(X_over)\n",
    "X_over.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # 80% training and 20% test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_base_models() Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_models():\n",
    "    models = dict()\n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_linear'] = SVC(kernel='linear')\n",
    "    models['svc_rbf'] = SVC()\n",
    "    models['svc_sigmoid'] = SVC(kernel='sigmoid')\n",
    "    models['svc_poly'] = SVC(kernel='poly')\n",
    "    return models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation based on k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********Cross Validation Score for each Model*********\n",
      ">Model: dt_ent, Mean Score: 0.809, Standard Deviation: 0.019\n",
      ">Model: lr, Mean Score: 0.821, Standard Deviation: 0.037\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models by cross validation score\n",
    "def evaluate_model_by_cv(X_over, y_over):\n",
    "    models = get_base_models()\n",
    "    score = dict()\n",
    "    for name, model in models.items():\n",
    "        scores = cross_val_score(model, X_over, y_over, scoring=\"recall_weighted\")\n",
    "        score[name] = scores\n",
    "    return score\n",
    "\n",
    "score = evaluate_model_by_cv(X_over, y_over)\n",
    "print('*********Cross Validation Score for each Model*********')\n",
    "for item in score:\n",
    "    print('>Model: %s, Mean Score: %.3f, Standard Deviation: %.3f' % (item, mean(score[item]), std(score[item])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Ensemble of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************Designing a Stacking Ensemble of Models**************\n",
    "\n",
    "def get_stacking():\n",
    "    # **************Defining the Base Models: Level=0 Models**************\n",
    "    level_0 = list()\n",
    "    level_0.append(('lr', LogisticRegression()))  # Model-A\n",
    "    level_0.append(('dt', DecisionTreeClassifier()))  # Model-B\n",
    "    level_0.append(('nb', SVC(kernel='linear')))  # Model-C\n",
    "    \n",
    "    # **************Defining the Meta Learner: Level=1**************\n",
    "    level_1 = LogisticRegression(max_iter=10000)\n",
    "    \n",
    "    # **************Designing the Stacking Ensemble of Models**************\n",
    "    model_stacking = StackingClassifier(estimators=level_0, final_estimator=level_1, cv=8)\n",
    "    return model_stacking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining get_ensemble_models() for Ensemble of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_models():\n",
    "    model_ensemble = dict()\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    model_ensemble['bagc'] = BaggingClassifier(estimator=lr, n_estimators=50, max_samples=0.8, max_features=0.8)\n",
    "    model_ensemble['boosting'] = AdaBoostClassifier(estimator=lr, n_estimators=10)  # 10 steps\n",
    "    model_ensemble['stack'] = get_stacking()\n",
    "    return model_ensemble"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing cross validation on Ensembles of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models by cross validation score\n",
    "def evaluate_model_by_cv(X_over, y_over):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    models = get_ensemble_models()\n",
    "    score = dict()\n",
    "    for name, model in models.items():\n",
    "        scores = cross_val_score(model, X_over, y_over, scoring=\"recall_weighted\")\n",
    "        score[name] = scores\n",
    "    return score\n",
    "\n",
    "score = evaluate_model_by_cv(X_over, y_over)\n",
    "print('*********Cross Validation Score for each Ensemble of Model*********')\n",
    "for item in score:\n",
    "    print('>Model: %s, Mean Score: %.3f, Standard Deviation: %.3f' % (item, mean(score[item]), std(score[item])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = BaggingClassifier(estimator=LogisticRegression(max_iter=10000), n_estimators=50, max_samples=0.8, max_features=0.8)\n",
    "best_model.fit(X_over, y_over)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = X_over.tail(1)\n",
    "prediction = best_model.predict(input)\n",
    "print('Prediction', prediction)\n",
    "y.tail(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

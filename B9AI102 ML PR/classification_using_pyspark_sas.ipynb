{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqLlo1OfBJ88"
      },
      "source": [
        "#MLLib for classification problem using PySpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE5J5uEvBHE8",
        "outputId": "1d3aea52-28e2-4b96-fe05-86be2fdaebb4"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 54 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 67.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=be4aaa7c80aa43bb1921f1a50f0a54570d50dae1aa5796d4234dd16ddf0e17b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhUdMozkBf4C"
      },
      "source": [
        "#   We'll start by loading the required libraries for this tutorial.\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.ml.feature import VectorAssembler \n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIlywDfcCXXB"
      },
      "source": [
        "# create a spark session \n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"ML using pyspark\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AXrOfHBoaTyr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsJTa___B4VB",
        "outputId": "c20c5e0a-edac-47e1-cd5e-d789486b57ce"
      },
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        " \n",
        "sqlContext = SQLContext(spark)\n",
        "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('Seed_Data.csv')\n",
        "df.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(A=15.26, P=14.84, C=0.871, LK=5.763, WK=3.312, A_Coef=2.221, LKG=5.22, target=0),\n",
              " Row(A=14.88, P=14.57, C=0.8811, LK=5.554, WK=3.333, A_Coef=1.018, LKG=4.956, target=0),\n",
              " Row(A=14.29, P=14.09, C=0.905, LK=5.291, WK=3.337, A_Coef=2.699, LKG=4.825, target=0),\n",
              " Row(A=13.84, P=13.94, C=0.8955, LK=5.324, WK=3.379, A_Coef=2.259, LKG=4.805, target=0),\n",
              " Row(A=16.14, P=14.99, C=0.9034, LK=5.658, WK=3.562, A_Coef=1.355, LKG=5.175, target=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "JOKD1c-2C6TC",
        "outputId": "f0673494-fbfd-4022-f4a2-6ba0f14d4655"
      },
      "source": [
        "df.describe()\n",
        "\n",
        "df.describe().toPandas().transpose()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>summary</th>\n",
              "      <td>count</td>\n",
              "      <td>mean</td>\n",
              "      <td>stddev</td>\n",
              "      <td>min</td>\n",
              "      <td>max</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A</th>\n",
              "      <td>210</td>\n",
              "      <td>14.847523809523816</td>\n",
              "      <td>2.9096994306873647</td>\n",
              "      <td>10.59</td>\n",
              "      <td>21.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P</th>\n",
              "      <td>210</td>\n",
              "      <td>14.559285714285718</td>\n",
              "      <td>1.3059587265640225</td>\n",
              "      <td>12.41</td>\n",
              "      <td>17.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C</th>\n",
              "      <td>210</td>\n",
              "      <td>0.8709985714285714</td>\n",
              "      <td>0.023629416583846364</td>\n",
              "      <td>0.8081</td>\n",
              "      <td>0.9183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LK</th>\n",
              "      <td>210</td>\n",
              "      <td>5.628533333333335</td>\n",
              "      <td>0.44306347772645016</td>\n",
              "      <td>4.899</td>\n",
              "      <td>6.675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WK</th>\n",
              "      <td>210</td>\n",
              "      <td>3.258604761904762</td>\n",
              "      <td>0.37771444490658673</td>\n",
              "      <td>2.63</td>\n",
              "      <td>4.033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A_Coef</th>\n",
              "      <td>210</td>\n",
              "      <td>3.7002009523809516</td>\n",
              "      <td>1.503557130821779</td>\n",
              "      <td>0.7651</td>\n",
              "      <td>8.456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LKG</th>\n",
              "      <td>210</td>\n",
              "      <td>5.408071428571429</td>\n",
              "      <td>0.4914804991024053</td>\n",
              "      <td>4.519</td>\n",
              "      <td>6.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>210</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.818447591071135</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             0                   1                     2       3       4\n",
              "summary  count                mean                stddev     min     max\n",
              "A          210  14.847523809523816    2.9096994306873647   10.59   21.18\n",
              "P          210  14.559285714285718    1.3059587265640225   12.41   17.25\n",
              "C          210  0.8709985714285714  0.023629416583846364  0.8081  0.9183\n",
              "LK         210   5.628533333333335   0.44306347772645016   4.899   6.675\n",
              "WK         210   3.258604761904762   0.37771444490658673    2.63   4.033\n",
              "A_Coef     210  3.7002009523809516     1.503557130821779  0.7651   8.456\n",
              "LKG        210   5.408071428571429    0.4914804991024053   4.519    6.55\n",
              "target     210                 1.0     0.818447591071135       0       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbh-4vabDGWR",
        "outputId": "307e4fe1-1a4b-43a9-c515-f21ba79ee990"
      },
      "source": [
        "#data prepration \n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "inputs=['A', 'P', 'C', 'LK', 'WK','A_Coef', 'LKG']\n",
        "vectorAssembler = VectorAssembler(inputCols = inputs, outputCol = 'features')\n",
        "v_df = vectorAssembler.transform(df)\n",
        "v_df = v_df.select(['features', 'target'])\n",
        "v_df.show(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+\n",
            "|            features|target|\n",
            "+--------------------+------+\n",
            "|[15.26,14.84,0.87...|     0|\n",
            "|[14.88,14.57,0.88...|     0|\n",
            "|[14.29,14.09,0.90...|     0|\n",
            "+--------------------+------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJAlDka0DsnB"
      },
      "source": [
        "#split the dataset\n",
        "\n",
        "splits = v_df.randomSplit([0.7, 0.3])\n",
        "train_df = splits[0]\n",
        "test_df = splits[1]\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JdboSiwe2_X"
      },
      "source": [
        "# apply logistic regression in pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCD0nfylfL44"
      },
      "source": [
        "train the model using trainset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfVlg_erB3DJ"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        " \n",
        "lr = LogisticRegression(featuresCol = 'features', labelCol = 'target', maxIter=10)\n",
        "lrModel = lr.fit(train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfmkrwC-fQIy"
      },
      "source": [
        "evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7BoBHc4HPnR",
        "outputId": "e5caadcb-b122-4a02-f803-a395cc453544"
      },
      "source": [
        " trainingSummary = lrModel.summary\n",
        "accuracy = trainingSummary.accuracy\n",
        "precision = trainingSummary.weightedPrecision\n",
        "recall = trainingSummary.weightedRecall\n",
        "print(accuracy,precision,recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9215686274509803 0.9215686274509804 0.9215686274509804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4oGLnnQJTE4"
      },
      "source": [
        "#Example 2: \n",
        "redo the task of classification using Decision Tree  classifier and compute the accuracy of the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEB0lwio-0av"
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        " \n",
        "dtc = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'target')\n",
        "dtcModel = dtc.fit(train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2F7oN8M-2X6",
        "outputId": "95b4bca5-9334-4c64-833d-c64d166e63ca"
      },
      "source": [
        "# Make predictions.\n",
        "predictions = dtcModel.transform(test_df)\n",
        "predictions\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[features: vector, target: int, rawPrediction: vector, probability: vector, prediction: double]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdpq-EbKAIr-",
        "outputId": "e16fff3e-faf4-4001-9b3f-50e398ec8bc1"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy = %g \" % (accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.929825 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mltf_gKoJZ0q"
      },
      "source": [
        "#Example 3: redo the task of classification using Random forest classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM-B5VX6ApwT"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1A7_ayDmbxk"
      },
      "source": [
        "#Example 4:\n",
        "use winequality-red dataset, to predict quality using logistic regression and dt classifier in pyspark. compute the value of accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH-WSFIooo42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24cffaa9-f661-40f6-a4ef-34c27647c07e"
      },
      "source": [
        " \n",
        "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('winequality-red.csv')\n",
        "df.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(fixed acidity=7.4, volatile acidity=0.7, citric acid=0.0, residual sugar=1.9, chlorides=0.076, free sulfur dioxide=11.0, total sulfur dioxide=34.0, density=0.9978, pH=3.51, sulphates=0.56, alcohol=9.4, quality=5),\n",
              " Row(fixed acidity=7.8, volatile acidity=0.88, citric acid=0.0, residual sugar=2.6, chlorides=0.098, free sulfur dioxide=25.0, total sulfur dioxide=67.0, density=0.9968, pH=3.2, sulphates=0.68, alcohol=9.8, quality=5),\n",
              " Row(fixed acidity=7.8, volatile acidity=0.76, citric acid=0.04, residual sugar=2.3, chlorides=0.092, free sulfur dioxide=15.0, total sulfur dioxide=54.0, density=0.997, pH=3.26, sulphates=0.65, alcohol=9.8, quality=5),\n",
              " Row(fixed acidity=11.2, volatile acidity=0.28, citric acid=0.56, residual sugar=1.9, chlorides=0.075, free sulfur dioxide=17.0, total sulfur dioxide=60.0, density=0.998, pH=3.16, sulphates=0.58, alcohol=9.8, quality=6),\n",
              " Row(fixed acidity=7.4, volatile acidity=0.7, citric acid=0.0, residual sugar=1.9, chlorides=0.076, free sulfur dioxide=11.0, total sulfur dioxide=34.0, density=0.9978, pH=3.51, sulphates=0.56, alcohol=9.4, quality=5)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SW3DRbPo4qB"
      },
      "source": [
        "#apply assembler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tTrar-Ko6jq",
        "outputId": "763069ad-3bdb-4c5a-dfe6-8d6eae7dd70a"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "inputs=['fixed acidity',\t'volatile acidity',\t'citric acid']\n",
        "vectorAssembler = VectorAssembler(inputCols = inputs, outputCol = 'features')\n",
        "v_df = vectorAssembler.transform(df)\n",
        "v_df = v_df.select(['features', 'quality'])\n",
        "v_df.show(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-------+\n",
            "|       features|quality|\n",
            "+---------------+-------+\n",
            "|  [7.4,0.7,0.0]|      5|\n",
            "| [7.8,0.88,0.0]|      5|\n",
            "|[7.8,0.76,0.04]|      5|\n",
            "+---------------+-------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhRcPlC9p4L2"
      },
      "source": [
        "#split the dataset\n",
        "\n",
        "splits = v_df.randomSplit([0.7, 0.3])\n",
        "train_df = splits[0]\n",
        "test_df = splits[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qyhz7SPfp-Vh"
      },
      "source": [
        "#apply logistic reg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcnPlEczqAg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97a7510-fb61-4f8d-83d3-537c01715982"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "lr = LogisticRegression(featuresCol = 'features', labelCol = 'quality', maxIter=10)\n",
        "lrModel = lr.fit(train_df)\n",
        "# Make predictions.\n",
        "pred_lr = lrModel.transform(test_df)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"quality\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(pred_lr)\n",
        "print(\"Accuracy = %g \" % (accuracy))\n",
        "Accuracy = 0.492341 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.492341 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhepsCQLbyYb",
        "outputId": "c1cc40d6-54f0-46f1-c198-81c59526804b"
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "#fit dt\n",
        "dtc = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'quality')\n",
        "dtcModel = dtc.fit(train_df)\n",
        "\n",
        "# Make predictions \n",
        "pred_dt = dtcModel.transform(test_df)\n",
        "\n",
        "# evaluate dt \n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"quality\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(pred_dt)\n",
        "print(\"Accuracy = %g \" % (accuracy))\n",
        "Accuracy = 0.461707"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.461707 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7CePdjAqJC7",
        "outputId": "8c4643e0-5cfc-4cb2-a4ac-740be1023a20"
      },
      "source": [
        " trainingSummary = lrModel.summary\n",
        "accuracy = trainingSummary.accuracy\n",
        "precision = trainingSummary.weightedPrecision\n",
        "recall = trainingSummary.weightedRecall\n",
        "print(accuracy,precision,recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4682971014492754 0.4041527984554447 0.4682971014492754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baOEhgOnqSfJ"
      },
      "source": [
        "#apply dt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6HfCDy-qRda",
        "outputId": "20de92a8-2998-47a1-d181-5fcf0255393e"
      },
      "source": [
        "#fit dt\n",
        "dtc = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'quality')\n",
        "dtcModel = dtc.fit(train_df)\n",
        "\n",
        "# Make predictions.\n",
        "predictions = dtcModel.transform(test_df)\n",
        "\n",
        " \n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"quality\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy = %g \" % (accuracy))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.492929 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ref:\n",
        "\n",
        "https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression\n"
      ],
      "metadata": {
        "id": "jzmDTwMp9g7X"
      }
    }
  ]
}
{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "use diamonds dataset to predict **price** in terms of other variables. For this, \n",
    "a. estimate the parameters\n",
    "b. select the imporant input features \n",
    "c. write down the predictive model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since price is practically continous therefore we need to apply linear regression:\n",
    "to do the following tasks:\n",
    "1.   parameter learning\n",
    "2.   feature selection\n",
    "3.   predictive model (use steps 1 and 2 and link function)\n",
    "4.   prediction \n",
    "5.   Evaluate the performance of prediction (split the dataset into trainset and testset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do Linear regression using 2 different ways:\n",
    "1.  using statistical learning\n",
    "2.  using sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data modeling:\n",
    "1. import the function of the model\n",
    "2. create the model\n",
    "3.  fit the model\n",
    "4. prediction using the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical way to recall GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import neccessary library\n",
    "from statistics import mean\n",
    "from statsmodels.api import GLM, add_constant, families\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('dataset/diamonds.csv')\n",
    "\n",
    "X = data.drop(['price', 'Unnamed: 0'], axis=1)  # Input variables\n",
    "y = data['price']  # Output variable\n",
    "\n",
    "OE = OrdinalEncoder(categories=[['Fair', 'Good', 'Very Good', 'Ideal', 'Premium']])\n",
    "\n",
    "data_cut_OE = OE.fit_transform(X[['cut']])\n",
    "data_cut_DF = DataFrame(data_cut_OE)\n",
    "data_cut_DF.columns = ['encoded cut']\n",
    "\n",
    "OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "data_color_OHE = OHE.fit_transform(X[['color']])\n",
    "data_color_DF = DataFrame(data_color_OHE.toarray())\n",
    "data_color_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "data_clarity_OHE = OHE.fit_transform(X[['clarity']])\n",
    "data_clarity_DF = DataFrame(data_clarity_OHE.toarray())\n",
    "data_clarity_DF.columns = OHE.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging multiple DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = concat([data_color_DF, data_clarity_DF], axis=1) # Excluding data_cut_DF since it is ordinal\n",
    "X_scalable = X[['carat', 'depth', 'table', 'length_mm', 'width_mm', 'depth_mm']]  # Orginal numeric columns\n",
    "X_scalable = concat([X_scalable, data_cut_DF], axis=1)  # Including encoded ordinal columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X_scalable)\n",
    "X_scaled_DF = DataFrame(X_scaled)\n",
    "X_scaled_DF.columns = X_scalable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PREP = concat([X_scaled_DF, X_binary], axis=1)  # Prepared Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling for feature selection / reduced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(X_PREP)  # Ading constant column to handle bias; \n",
    "model_full = GLM(y, X, family=families.Gaussian(families.links.log())).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = dict(model_full.pvalues)  # Identifying the columns to drop\n",
    "drop_columns = []\n",
    "for x in pvalues:\n",
    "    if pvalues[x] >= 0.05:\n",
    "        drop_columns.append(x)\n",
    "# print(drop_columns)\n",
    "X_red = X.drop(drop_columns, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive Model:  yhat=5.455245+0.001909*ZN+0.022373*INDUS+0.028275*RAD-0.002238*MEDV    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[225.3099879525569, 228.72941658063053]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_full = []\n",
    "rmse_red = []\n",
    "for i in range(20):\n",
    "    X = add_constant(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    #*************Full Data Modelling*************\n",
    "    \n",
    "    # Creating the Linear Regression Model\n",
    "    model_full = GLM(y_train, X_train, family=families.Gaussian(families.links.log())).fit()\n",
    "\n",
    "    # Predicting using Test-set\n",
    "    pred_full = model_full.predict(X_test)\n",
    "    rmse_full.append(sqrt(mean_squared_error(y_test, pred_full)))\n",
    "    \n",
    "    #*************Reduced Data Modelling*************\n",
    "    \n",
    "    # Creating the Linear Regression Model\n",
    "    X = add_constant(X_red)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model_reduced = GLM(y_train, X_train, family=families.Gaussian(families.links.log())).fit()\n",
    "    \n",
    "    # Predicting using Test-set\n",
    "    pred_red = model_reduced.predict(X_test)\n",
    "    rmse_red.append(sqrt(mean_squared_error(y_test, pred_red)))\n",
    "\n",
    "[mean(rmse_full), mean(rmse_red)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(X_red)\n",
    "model_dep = GLM(y, X, family=families.Gaussian(families.links.log())).fit()  # create the linear reg model using"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858    2824.675874\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "858    2871\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = X.tail(1)\n",
    "pred_red = model_dep.predict(new)\n",
    "print(pred_red)\n",
    "y.tail(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical & sklearn way to recall GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary library\n",
    "from statistics import mean\n",
    "from statsmodels.api import GLM, add_constant, families\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('dataset/diamonds.csv')\n",
    "\n",
    "X = data.drop(['price', 'Unnamed: 0'], axis=1)  # Input variables\n",
    "y = data['price']  # Output variable\n",
    "\n",
    "OE = OrdinalEncoder(categories=[['Fair', 'Good', 'Very Good', 'Ideal', 'Premium']])\n",
    "data_cut_OE = OE.fit_transform(X[['cut']])\n",
    "data_cut_DF = DataFrame(data_cut_OE)\n",
    "data_cut_DF.columns = ['encoded cut']\n",
    "\n",
    "OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "data_color_OHE = OHE.fit_transform(X[['color']])\n",
    "data_color_DF = DataFrame(data_color_OHE.toarray())\n",
    "data_color_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "data_clarity_OHE = OHE.fit_transform(X[['clarity']])\n",
    "data_clarity_DF = DataFrame(data_clarity_OHE.toarray())\n",
    "data_clarity_DF.columns = OHE.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging multiple DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = concat([data_color_DF, data_clarity_DF], axis=1) # Excluding data_cut_DF since it is ordinal\n",
    "X_scalable = X[['carat', 'depth', 'table', 'length_mm', 'width_mm', 'depth_mm']]  # Orginal numeric columns\n",
    "X_scalable = concat([X_scalable, data_cut_DF], axis=1) # Including encoded ordinal columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying standard scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X_scalable)\n",
    "X_scaled_DF = DataFrame(X_scaled)\n",
    "X_scaled_DF.columns = X_scalable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PREP = concat([X_scaled_DF, X_binary], axis=1)  # Prepared Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling for feature selection / reduced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(X_PREP)  # Ading constant column to handle bias\n",
    "model_full = GLM(y, X, family=families.Gaussian(families.links.log())).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = dict(model_full.pvalues)  # Identifying the columns to drop\n",
    "drop_columns = []\n",
    "for x in pvalues:\n",
    "    if pvalues[x] >= 0.05:\n",
    "        drop_columns.append(x)\n",
    "# print(drop_columns)\n",
    "X_red = X.drop(drop_columns, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive Model:  yhat=5.455245+0.001909*ZN+0.022373*INDUS+0.028275*RAD-0.002238*MEDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[231.3826222352573, 221.00936319241126, 164.57963498013402, 158.71981793809638]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_st_full = []\n",
    "rmse_st_red = []\n",
    "rmse_skl_full = []\n",
    "rmse_skl_red = []\n",
    "\n",
    "model_skl = LinearRegression()\n",
    "for i in range(20):\n",
    "    #************************* Full Data Modelling  ***************************#\n",
    "    X = add_constant(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # statsmodels\n",
    "    model_st_full = GLM(y_train, X_train, family=families.Gaussian(families.links.log())).fit()\n",
    "\n",
    "    # Predicting using Test-set\n",
    "    pred_st_full = model_st_full.predict(X_test)\n",
    "    rmse_st_full.append(sqrt(mean_squared_error(y_test, pred_st_full)))\n",
    "    \n",
    "    # sklearn\n",
    "    model_skl.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting using Test-set\n",
    "    pred_skl_full = model_skl.predict(X_test)\n",
    "    rmse_skl_full.append(sqrt(mean_squared_error(y_test, pred_skl_full)))\n",
    "    \n",
    "    #************************* Reduced Data Modelling  ***************************#\n",
    "    X = add_constant(X_red)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # statsmodels\n",
    "    model_st_red = GLM(y_train, X_train, family=families.Gaussian(families.links.log())).fit()  # create the linear reg model using\n",
    "    \n",
    "    # Predicting using Test-set\n",
    "    pred_red = model_reduced.predict(X_test)\n",
    "    rmse_st_red.append(sqrt(mean_squared_error(y_test, pred_red)))\n",
    "    \n",
    "    # sklearn\n",
    "    model_skl.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting using Test-set\n",
    "    pred_skl_red = model_skl.predict(X_test)\n",
    "    rmse_skl_red.append(sqrt(mean_squared_error(y_test, pred_skl_red)))\n",
    "    \n",
    "\n",
    "[mean(rmse_st_full), mean(rmse_st_red), mean(rmse_skl_full), mean(rmse_skl_red)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(X_red)\n",
    "model_skl_red_dep = model_skl.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using Test-set\n",
    "# Predict the tax using the linear regression for the last row in the boston_house-prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2809.03468253]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "858    2871\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model_skl_red_dep.predict(X.tail(1))\n",
    "print(prediction)\n",
    "y.tail(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "Use boston_house price dataset, \n",
    "1.   Consider CHAS as the output variable \n",
    "2.   the remaining variables are inputs \n",
    "apply logistic regression to do the following tasks:\n",
    "*  parameter estimation \n",
    "*   attribute selection \n",
    "*  predictive model\n",
    "*   prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary library\n",
    "from statistics import mean\n",
    "from statsmodels.api import GLM, add_constant, families\n",
    "from pandas import read_csv, DataFrame\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import accuracy_score, recall_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_csv('dataset/boston_house_prices.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CHAS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('CHAS', axis=1)  # input\n",
    "y = data['CHAS']   # output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling for feature selection / reduced model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(X)  # add intercept\n",
    "model_st = GLM(y, X, family=families.Binomial()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = dict(model_st.pvalues)  # Identifying the columns to drop\n",
    "drop_columns = []\n",
    "for x in pvalues:\n",
    "    if pvalues[x] >= 0.05:\n",
    "        drop_columns.append(x)\n",
    "# print(\"Columns to be romoved:\", drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = X.drop(drop_columns, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=3)  # testset is 10%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive model based on above results:\n",
    "\n",
    "that_i = 0.0952 * INDUS_i + 0.2191 * RAD_i - 0.0087 * TAX_i + 0.0693 * MEDV_i\n",
    "\n",
    "1.   phat_i = 1 / (1 + exp(-that_i))\n",
    "2.   yhat_i = 1 if phat_i >= 0.5 else yhat_i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_st_red = GLM(y_train, X_train, family=families.Binomial()).fit() # logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_st_raw = model_st_red.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting predictions to binary predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction  Actual\n",
       "224           0       0\n",
       "137           0       0\n",
       "453           0       0\n",
       "303           0       0\n",
       "254           0       0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_st = [1 if prediction > 0.5 else 0 for prediction in prediction_st_raw]\n",
    "df = DataFrame({\"Prediction\": prediction_st, \"Actual\": y_test})\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_skl = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "prediction_skl = model_skl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction_st</th>\n",
       "      <th>Prediction_skl</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction_st  Prediction_skl  Actual\n",
       "224              0               0       0\n",
       "137              0               0       0\n",
       "453              0               0       0\n",
       "303              0               0       0\n",
       "254              0               0       0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame({\"Prediction_st\": prediction_st, \"Prediction_skl\": prediction_skl, \"Actual\": y_test})\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute recall and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8823529411764706, 0.8823529411764706]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction_st\n",
    "acc_st = accuracy_score(y_test, prediction_st)\n",
    "re_st = recall_score(y_test, prediction_st)\n",
    "acc_skl = accuracy_score(y_test, prediction_skl)\n",
    "re_skl = recall_score(y_test, prediction_skl)\n",
    "print([acc_st, acc_skl])\n",
    "[re_st, re_skl]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Example\n",
    "\n",
    "Use **winequality-red** dataset, apply NB classifier to predict **quality** variable. to do so, \n",
    "\n",
    "1. split the dataset into 70/30%\n",
    "\n",
    "2. evaluate the model using **accurary** and **recall**.\n",
    "\n",
    "3. validate the result using MC sampling with mc=100. \n",
    "\n",
    "4. predict the quality for a give set of input variables. \n",
    "\n",
    "5. redo the classification task using logistic regression and compare the result versus Naive Bayes classifier in 100 MC runs. Specify the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset/winequality-red.csv')\n",
    "X = dataset.drop('quality', axis=1)  # Input variables\n",
    "y = dataset['quality']  # Output variable\n",
    "# y.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5416666666666666, 0.5416666666666666]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)  # 70% training and 30% testgnb = GaussianNB()\n",
    "gnb = GaussianNB().fit(X_train, y_train) # Train the model using the training sets\n",
    "\n",
    "prediction = gnb.predict(X_test)  # Predict the response for test dataset\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction, average='micro')\n",
    "[accuracy, recall]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation using Monte Calro sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5419291666666666"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "for r in range(1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    gnb = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "    prediction = gnb.predict(X_test)  # Predict the response for test dataset\n",
    "    accuracy.append(accuracy_score(y_test, prediction))\n",
    "mean(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation based on Cross Validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5278293178973718"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "scores = cross_val_score(gnb, X, y, cv=2)\n",
    "mean(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction: for the last sample in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=int64)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input = X.tail(1)\n",
    "gnb.fit(X, y)\n",
    "gnb.predict(X_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Use iris dataset\n",
    "1.  Fit the Naive Bayes classifier  and evaluate the accuracy of the model in 100 mc runs. use 80% as the trainset and 20% testset.\n",
    "2.  Recommend the type of flower for the following sample: X=[4,1,2,3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('dataset/Iris.csv')\n",
    "X = dataset.drop('Species', axis=1)  # Input variables\n",
    "y = dataset['Species']  # Output variable\n",
    "# y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9538666666666666"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    gnb.fit(X_train, y_train)\n",
    "    prediction = gnb.predict(X_test)\n",
    "    accuracy.append(accuracy_score(prediction, y_test))\n",
    "valid_acc = mean(accuracy)\n",
    "valid_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-fold cross-validtion \n",
    "Validate the accuracy of GNB using 3 fold cross validation technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9533333333333335"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(gnb, X, y, cv=50)\n",
    "mean(cv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-virginica'], dtype='<U15')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gnb = gnb.fit(X.values, y.values) # Warning resoved\n",
    "input = [[4, 1, 2, 3]]\n",
    "model_gnb.predict(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logistic = LogisticRegression(max_iter=10000) # Warning resolved\n",
    "accuracy = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    model_logistic.fit(X_train, y_train)\n",
    "    prediction = model_logistic.predict(X_test)\n",
    "    accuracy.append(accuracy_score(prediction, y_test))\n",
    "valid_acc = mean(accuracy)\n",
    "valid_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: predict **Species** in the **Iris** dataset using Support Vector Machine. \n",
    "*   train the model using 80% and evaluate it based on 20% testset\n",
    "*   apply svm for different kernels\n",
    "*   validate the result in 100 MC runs\n",
    "*   Recommend the type of flower for the first sample in the dataset using the best classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('dataset/Iris.csv')\n",
    "X = dataset.drop('Species', axis=1)  # Input variables\n",
    "y = dataset['Species']  # Output variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm for different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9777777777777777,\n",
       " 0.9555555555555556,\n",
       " 0.9555555555555556,\n",
       " 0.24444444444444444]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)  # testset is 30%\n",
    "    model = SVC(kernel=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, prediction))\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the result of performance for different kernels of svc in 100 MC runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9740000000000002, 0.964, 0.9593333333333333, 0.2515555555555555]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    accuracy_mc = []\n",
    "    for j in range(100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=j)  # testset is 30%\n",
    "        model = SVC(kernel=i, C=1.1)\n",
    "        model.fit(X_train, y_train)\n",
    "        prediction = model.predict(X_test)\n",
    "        accuracy_mc.append(accuracy_score(y_test, prediction))  # append accuracy score in each MC run\n",
    "    accuracy.append(mean(accuracy_mc)) # mean of accuracy and append it in accuracy in kernel array\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-fold cross validation score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9733333333333334,\n",
       " 0.9666666666666668,\n",
       " 0.9733333333333334,\n",
       " 0.06666666666666668]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    model = SVC(kernel=i)\n",
    "    cross_v_score = cross_val_score(model, X, y, scoring='accuracy', cv=10) # cv=10: 10-fold cross validation\n",
    "    # mean of accuracy and append it in accuracy in kernel array\n",
    "    accuracy.append(mean(cross_v_score))\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat the above expriment for NB classifier and logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.98, 0.96, 0.98, 0.16666666666666666],\n",
       " 0.9666666666666667,\n",
       " 0.9533333333333333]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_svc = []\n",
    "accuracy_gnb = []\n",
    "accuracy_lr = []\n",
    "\n",
    "model_lr = LogisticRegression(max_iter=10000)\n",
    "model_gnb = GaussianNB()\n",
    "\n",
    "cross_v_score_lr = cross_val_score(model_lr, X, y, scoring='accuracy', cv=6)\n",
    "cross_v_score_gnb = cross_val_score(gnb, X, y, scoring='accuracy', cv=6)\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    model_svc = SVC(kernel=i)\n",
    "    cross_v_score_svc = cross_val_score(model_svc, X, y, scoring='accuracy', cv=6)\n",
    "    accuracy_svc.append(mean(cross_v_score_svc)) # mean of accuracy and append it in accuracy in kernel array\n",
    "accuracy = [accuracy_svc, mean(cross_v_score_lr), mean(cross_v_score_gnb)]\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Gini index to specify the root node of the decision tree for playtennis dataset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: \n",
    "use decision tree algorithm with gini and entropy rules to predict the species of flowers in the Iris dataset, and compare the result versus SVC and Multinomial logistic regression in 1000 mc runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier # decision tee algorithm for classification\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset/Iris.csv')\n",
    "X = dataset.drop('Species', axis=1)  # matrix of input variables\n",
    "y = dataset['Species']  # output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                 precision    recall  f1-score   support\\n\\n    Iris-setosa       1.00      1.00      1.00        11\\nIris-versicolor       0.89      1.00      0.94         8\\n Iris-virginica       1.00      0.91      0.95        11\\n\\n       accuracy                           0.97        30\\n      macro avg       0.96      0.97      0.96        30\\n   weighted avg       0.97      0.97      0.97        30\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # split dataset\n",
    "model_dt = dt.fit(X_train, y_train)  # fit the model\n",
    "prediction = model_dt.predict(X_test)  # prediction\n",
    "recall = recall_score(y_test, prediction, average='weighted')  # compute recall\n",
    "recall\n",
    "classification_report(y_test, prediction)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_l'] = SVC(kernel='linear')\n",
    "    models['svc_r'] = SVC()\n",
    "    models['svc_s'] = SVC(kernel='sigmoid')\n",
    "    models['svc_p'] = SVC(kernel='poly')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, mc_run, split):\n",
    "    accuracy = [] \n",
    "    for i in range(mc_run):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split)  # split dataset\n",
    "        m = model.fit(X_train, y_train)  # fit the model\n",
    "        prediction = m.predict(X_test)  # prediction\n",
    "        accuracy.append(accuracy_score(y_test, prediction))  # compute & append accuracy\n",
    "        return mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dt_ent', 0.9666666666666667)\n",
      "('dt_gini', 0.9666666666666667)\n",
      "('lr', 0.9666666666666667)\n",
      "('svc_l', 1.0)\n",
      "('svc_r', 0.9333333333333333)\n",
      "('svc_s', 0.2)\n",
      "('svc_p', 1.0)\n"
     ]
    }
   ],
   "source": [
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y, 100, 0.2)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print((name, mean(scores)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the models in dictionary using k-fold cross validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_models defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    models['dt_ent'] = DecisionTreeClassifier(criterion='entropy')\n",
    "    models['dt_gini'] = DecisionTreeClassifier(criterion='gini')\n",
    "    models['lr'] = LogisticRegression(max_iter=10000)\n",
    "    models['svc_l'] = SVC(kernel='linear')\n",
    "    models['svc_r'] = SVC()\n",
    "    models['svc_s'] = SVC(kernel='sigmoid')\n",
    "    models['svc_p'] = SVC(kernel='poly')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_evaluator(model, X, y, k_fold):\n",
    "    scores = cross_val_score(model, X, y, cv=k_fold)\n",
    "    return mean(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following result is the accuracy of different model in the dictionary of SML based on 6-fold cross validation\n",
      "('dt_ent', 0.9533333333333333)\n",
      "('dt_gini', 0.9533333333333333)\n",
      "('lr', 0.9666666666666667)\n",
      "('svc_l', 0.98)\n",
      "('svc_r', 0.98)\n",
      "('svc_s', 0.16666666666666666)\n",
      "('svc_p', 0.96)\n"
     ]
    }
   ],
   "source": [
    "models = get_models() # Get the model list to be evaluated\n",
    "results, names = list(), list()\n",
    "print('The following result is the accuracy of different model in the dictionary of SML based on 6-fold cross validation')\n",
    "for name, model in models.items():\n",
    "    scores = cross_evaluator(model, X, y, 6)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print((name, mean(scores)))\n",
    "# plot model performance for comparison\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

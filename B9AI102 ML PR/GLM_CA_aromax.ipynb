{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "use diamonds dataset to predict **price** in terms of other variables. For this, \n",
    "a. estimate the parameters\n",
    "b. select the imporant input features \n",
    "c. write down the predictive model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since price is practically continous therefore we need to apply linear regression:\n",
    "to do the following tasks:\n",
    "1.   parameter learning\n",
    "2.   feature selection\n",
    "3.   predictive model (use steps 1 and 2 and link function)\n",
    "4.   prediction \n",
    "5.   Evaluate the performance of prediction (split the dataset into trainset and testset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do Linear regression using 2 different ways:\n",
    "1.  using statistical learning\n",
    "2.  using sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data modeling:\n",
    "1. import the function of the model\n",
    "2. create the model\n",
    "3.  fit the model\n",
    "4. prediction using the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical way to recall GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import neccessary library\n",
    "from statistics import mean\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import GLM, add_constant\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('dataset/diamonds.csv')\n",
    "\n",
    "X = data.drop(['price', 'Unnamed: 0'], axis=1)  # Input variables\n",
    "y = data['price']  # Output variable\n",
    "\n",
    "OE = OrdinalEncoder(categories=[['Fair', 'Good', 'Very Good', 'Ideal', 'Premium']])\n",
    "\n",
    "data_cut_OE = OE.fit_transform(X[['cut']])\n",
    "data_cut_DF = DataFrame(data_cut_OE)\n",
    "data_cut_DF.columns = ['encoded cut']\n",
    "\n",
    "OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "data_color_OHE = OHE.fit_transform(X[['color']])\n",
    "data_color_DF = DataFrame(data_color_OHE.toarray())\n",
    "data_color_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "data_clarity_OHE = OHE.fit_transform(X[['clarity']])\n",
    "data_clarity_DF = DataFrame(data_clarity_OHE.toarray())\n",
    "data_clarity_DF.columns = OHE.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging multiple DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = concat([data_color_DF, data_clarity_DF], axis=1) # Excluding data_cut_DF since it is ordinal\n",
    "X_scalable = X[['carat', 'depth', 'table', 'length_mm', 'width_mm', 'depth_mm']]  # Orginal numeric columns\n",
    "X_scalable = concat([X_scalable, data_cut_DF], axis=1)  # Including encoded ordinal columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X_scalable)\n",
    "X_scaled_DF = DataFrame(X_scaled)\n",
    "X_scaled_DF.columns = X_scalable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PREP = concat([X_scaled_DF, X_binary], axis=1)  # Prepared Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling for feature selection / reduced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>price</td>      <th>  No. Observations:  </th>   <td>   859</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>   <td>   838</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Gaussian</td>     <th>  Df Model:          </th>   <td>    20</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>log</td>       <th>  Scale:             </th>  <td>  50649.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th>  <td> -5861.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 08 Mar 2023</td> <th>  Deviance:          </th> <td>4.2444e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>02:11:25</td>     <th>  Pearson chi2:      </th>  <td>4.24e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>22</td>        <th>  Pseudo R-squ. (CS):</th>   <td> 1.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    6.0650</td> <td>    0.005</td> <td> 1159.381</td> <td> 0.000</td> <td>    6.055</td> <td>    6.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carat</th>        <td>   -0.5882</td> <td>    0.039</td> <td>  -14.960</td> <td> 0.000</td> <td>   -0.665</td> <td>   -0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth</th>        <td>   -0.0430</td> <td>    0.045</td> <td>   -0.958</td> <td> 0.338</td> <td>   -0.131</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>table</th>        <td>    0.0243</td> <td>    0.004</td> <td>    6.350</td> <td> 0.000</td> <td>    0.017</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length_mm</th>    <td>    0.0201</td> <td>    0.099</td> <td>    0.203</td> <td> 0.839</td> <td>   -0.174</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>width_mm</th>     <td>    0.3744</td> <td>    0.092</td> <td>    4.087</td> <td> 0.000</td> <td>    0.195</td> <td>    0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_mm</th>     <td>    0.7281</td> <td>    0.171</td> <td>    4.270</td> <td> 0.000</td> <td>    0.394</td> <td>    1.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>encoded cut</th>  <td>    0.0122</td> <td>    0.003</td> <td>    3.517</td> <td> 0.000</td> <td>    0.005</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_D</th>      <td>    0.9806</td> <td>    0.009</td> <td>  111.662</td> <td> 0.000</td> <td>    0.963</td> <td>    0.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_E</th>      <td>    0.9480</td> <td>    0.007</td> <td>  139.634</td> <td> 0.000</td> <td>    0.935</td> <td>    0.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_F</th>      <td>    0.9357</td> <td>    0.007</td> <td>  138.875</td> <td> 0.000</td> <td>    0.923</td> <td>    0.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_G</th>      <td>    0.8831</td> <td>    0.008</td> <td>  113.083</td> <td> 0.000</td> <td>    0.868</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_H</th>      <td>    0.8194</td> <td>    0.009</td> <td>   94.732</td> <td> 0.000</td> <td>    0.802</td> <td>    0.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_I</th>      <td>    0.7579</td> <td>    0.011</td> <td>   67.488</td> <td> 0.000</td> <td>    0.736</td> <td>    0.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_J</th>      <td>    0.7402</td> <td>    0.016</td> <td>   44.962</td> <td> 0.000</td> <td>    0.708</td> <td>    0.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_I1</th>   <td>    0.4579</td> <td>    0.023</td> <td>   20.128</td> <td> 0.000</td> <td>    0.413</td> <td>    0.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_IF</th>   <td>    0.9950</td> <td>    0.022</td> <td>   45.326</td> <td> 0.000</td> <td>    0.952</td> <td>    1.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_SI1</th>  <td>    0.6948</td> <td>    0.007</td> <td>  101.299</td> <td> 0.000</td> <td>    0.681</td> <td>    0.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_SI2</th>  <td>    0.5914</td> <td>    0.009</td> <td>   62.388</td> <td> 0.000</td> <td>    0.573</td> <td>    0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_VS1</th>  <td>    0.7624</td> <td>    0.008</td> <td>   91.078</td> <td> 0.000</td> <td>    0.746</td> <td>    0.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_VS2</th>  <td>    0.7443</td> <td>    0.007</td> <td>  105.410</td> <td> 0.000</td> <td>    0.730</td> <td>    0.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_VVS1</th> <td>    0.9429</td> <td>    0.014</td> <td>   67.375</td> <td> 0.000</td> <td>    0.916</td> <td>    0.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_VVS2</th> <td>    0.8762</td> <td>    0.012</td> <td>   72.099</td> <td> 0.000</td> <td>    0.852</td> <td>    0.900</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   No. Observations:                  859\n",
       "Model:                            GLM   Df Residuals:                      838\n",
       "Model Family:                Gaussian   Df Model:                           20\n",
       "Link Function:                    log   Scale:                          50649.\n",
       "Method:                          IRLS   Log-Likelihood:                -5861.0\n",
       "Date:                Wed, 08 Mar 2023   Deviance:                   4.2444e+07\n",
       "Time:                        02:11:25   Pearson chi2:                 4.24e+07\n",
       "No. Iterations:                    22   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            6.0650      0.005   1159.381      0.000       6.055       6.075\n",
       "carat           -0.5882      0.039    -14.960      0.000      -0.665      -0.511\n",
       "depth           -0.0430      0.045     -0.958      0.338      -0.131       0.045\n",
       "table            0.0243      0.004      6.350      0.000       0.017       0.032\n",
       "length_mm        0.0201      0.099      0.203      0.839      -0.174       0.215\n",
       "width_mm         0.3744      0.092      4.087      0.000       0.195       0.554\n",
       "depth_mm         0.7281      0.171      4.270      0.000       0.394       1.062\n",
       "encoded cut      0.0122      0.003      3.517      0.000       0.005       0.019\n",
       "color_D          0.9806      0.009    111.662      0.000       0.963       0.998\n",
       "color_E          0.9480      0.007    139.634      0.000       0.935       0.961\n",
       "color_F          0.9357      0.007    138.875      0.000       0.923       0.949\n",
       "color_G          0.8831      0.008    113.083      0.000       0.868       0.898\n",
       "color_H          0.8194      0.009     94.732      0.000       0.802       0.836\n",
       "color_I          0.7579      0.011     67.488      0.000       0.736       0.780\n",
       "color_J          0.7402      0.016     44.962      0.000       0.708       0.772\n",
       "clarity_I1       0.4579      0.023     20.128      0.000       0.413       0.502\n",
       "clarity_IF       0.9950      0.022     45.326      0.000       0.952       1.038\n",
       "clarity_SI1      0.6948      0.007    101.299      0.000       0.681       0.708\n",
       "clarity_SI2      0.5914      0.009     62.388      0.000       0.573       0.610\n",
       "clarity_VS1      0.7624      0.008     91.078      0.000       0.746       0.779\n",
       "clarity_VS2      0.7443      0.007    105.410      0.000       0.730       0.758\n",
       "clarity_VVS1     0.9429      0.014     67.375      0.000       0.916       0.970\n",
       "clarity_VVS2     0.8762      0.012     72.099      0.000       0.852       0.900\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = add_constant(X_PREP)  # Ading constant column to handle bias; \n",
    "model_full = GLM(y, X, family=sm.families.Gaussian(sm.families.links.log()))\n",
    "res = model_full.fit()  # Fitting the model\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth\n",
      "length_mm\n"
     ]
    }
   ],
   "source": [
    "pvalues = dict(res.pvalues)  # Identifying the columns to drop\n",
    "for x in pvalues:\n",
    "    if pvalues[x] >= 0.05:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = X.drop(['depth', 'length_mm'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive Model:  yhat=5.455245+0.001909*ZN+0.022373*INDUS+0.028275*RAD-0.002238*MEDV    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[228.95992067970442, 230.3011580919856]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_full = []\n",
    "rmse_red = []\n",
    "for i in range(20):\n",
    "    X = add_constant(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    #*************Full Data Modelling*************\n",
    "    \n",
    "    # Creating the Linear Regression Model\n",
    "    model_full_train = GLM(y_train, X_train, family=sm.families.Gaussian(sm.families.links.log()))\n",
    "    model_full = model_full_train.fit()  # Fitting the model\n",
    "    model_full.summary()\n",
    "\n",
    "    # Predicting using Test-set\n",
    "    pred_full = model_full.predict(X_test)\n",
    "    rmse1 = sqrt(mean_squared_error(y_test, pred_full))\n",
    "    rmse_full.append(rmse1)\n",
    "    \n",
    "    #*************Reduced Data Modelling*************\n",
    "    \n",
    "    # Creating the Linear Regression Model\n",
    "    X = add_constant(X_red)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model_reduced_train = GLM(y_train, X_train, family=sm.families.Gaussian(sm.families.links.log()))\n",
    "    model_reduced = model_reduced_train.fit()\n",
    "    \n",
    "    # Predicting using Test-set\n",
    "    pred_red = model_reduced.predict(X_test)\n",
    "    rmse2 = sqrt(mean_squared_error(y_test, pred_red))\n",
    "    rmse_red.append(rmse2)\n",
    "\n",
    "[mean(rmse_full), mean(rmse_red)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(X_red)\n",
    "model_train = GLM(y, X, family=sm.families.Gaussian(sm.families.links.log()))  # create the linear reg model using\n",
    "red_model = model_train.fit() # fit the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858    2824.587072\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "858    2871\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = X.tail(1)\n",
    "pred_red = red_model.predict(new)\n",
    "print(pred_red)\n",
    "y.tail(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical & sklearn way to recall GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary library\n",
    "from statistics import mean\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import GLM, add_constant\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('dataset/diamonds.csv')\n",
    "\n",
    "X = data.drop(['price', 'Unnamed: 0'], axis=1)  # Input variables\n",
    "y = data['price']  # Output variable\n",
    "\n",
    "OE = OrdinalEncoder(categories=[['Fair', 'Good', 'Very Good', 'Ideal', 'Premium']])\n",
    "data_cut_OE = OE.fit_transform(X[['cut']])\n",
    "data_cut_DF = DataFrame(data_cut_OE)\n",
    "data_cut_DF.columns = ['encoded cut']\n",
    "\n",
    "OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "data_color_OHE = OHE.fit_transform(X[['color']])\n",
    "data_color_DF = DataFrame(data_color_OHE.toarray())\n",
    "data_color_DF.columns = OHE.get_feature_names_out()\n",
    "\n",
    "data_clarity_OHE = OHE.fit_transform(X[['clarity']])\n",
    "data_clarity_DF = DataFrame(data_clarity_OHE.toarray())\n",
    "data_clarity_DF.columns = OHE.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging multiple DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = concat([data_color_DF, data_clarity_DF], axis=1) # Excluding data_cut_DF since it is ordinal\n",
    "X_scalable = X[['carat', 'depth', 'table', 'length_mm', 'width_mm', 'depth_mm']]  # Orginal numeric columns\n",
    "X_scalable = concat([X_scalable, data_cut_DF], axis=1) # Including encoded ordinal columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying standard scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X_scalable)\n",
    "X_scaled_DF = DataFrame(X_scaled)\n",
    "X_scaled_DF.columns = X_scalable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PREP = concat([X_scaled_DF, X_binary], axis=1)  # Prepared Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling for feature selection / reduced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>price</td>      <th>  No. Observations:  </th>   <td>   859</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>   <td>   838</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Gaussian</td>     <th>  Df Model:          </th>   <td>    20</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>log</td>       <th>  Scale:             </th>  <td>  50649.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th>  <td> -5861.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 08 Mar 2023</td> <th>  Deviance:          </th> <td>4.2444e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>02:23:04</td>     <th>  Pearson chi2:      </th>  <td>4.24e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>22</td>        <th>  Pseudo R-squ. (CS):</th>   <td> 1.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    6.0650</td> <td>    0.005</td> <td> 1159.381</td> <td> 0.000</td> <td>    6.055</td> <td>    6.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carat</th>        <td>   -0.5882</td> <td>    0.039</td> <td>  -14.960</td> <td> 0.000</td> <td>   -0.665</td> <td>   -0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth</th>        <td>   -0.0430</td> <td>    0.045</td> <td>   -0.958</td> <td> 0.338</td> <td>   -0.131</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>table</th>        <td>    0.0243</td> <td>    0.004</td> <td>    6.350</td> <td> 0.000</td> <td>    0.017</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length_mm</th>    <td>    0.0201</td> <td>    0.099</td> <td>    0.203</td> <td> 0.839</td> <td>   -0.174</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>width_mm</th>     <td>    0.3744</td> <td>    0.092</td> <td>    4.087</td> <td> 0.000</td> <td>    0.195</td> <td>    0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_mm</th>     <td>    0.7281</td> <td>    0.171</td> <td>    4.270</td> <td> 0.000</td> <td>    0.394</td> <td>    1.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>encoded cut</th>  <td>    0.0122</td> <td>    0.003</td> <td>    3.517</td> <td> 0.000</td> <td>    0.005</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_D</th>      <td>    0.9806</td> <td>    0.009</td> <td>  111.662</td> <td> 0.000</td> <td>    0.963</td> <td>    0.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_E</th>      <td>    0.9480</td> <td>    0.007</td> <td>  139.634</td> <td> 0.000</td> <td>    0.935</td> <td>    0.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_F</th>      <td>    0.9357</td> <td>    0.007</td> <td>  138.875</td> <td> 0.000</td> <td>    0.923</td> <td>    0.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_G</th>      <td>    0.8831</td> <td>    0.008</td> <td>  113.083</td> <td> 0.000</td> <td>    0.868</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_H</th>      <td>    0.8194</td> <td>    0.009</td> <td>   94.732</td> <td> 0.000</td> <td>    0.802</td> <td>    0.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_I</th>      <td>    0.7579</td> <td>    0.011</td> <td>   67.488</td> <td> 0.000</td> <td>    0.736</td> <td>    0.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color_J</th>      <td>    0.7402</td> <td>    0.016</td> <td>   44.962</td> <td> 0.000</td> <td>    0.708</td> <td>    0.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_I1</th>   <td>    0.4579</td> <td>    0.023</td> <td>   20.128</td> <td> 0.000</td> <td>    0.413</td> <td>    0.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_IF</th>   <td>    0.9950</td> <td>    0.022</td> <td>   45.326</td> <td> 0.000</td> <td>    0.952</td> <td>    1.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_SI1</th>  <td>    0.6948</td> <td>    0.007</td> <td>  101.299</td> <td> 0.000</td> <td>    0.681</td> <td>    0.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_SI2</th>  <td>    0.5914</td> <td>    0.009</td> <td>   62.388</td> <td> 0.000</td> <td>    0.573</td> <td>    0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_VS1</th>  <td>    0.7624</td> <td>    0.008</td> <td>   91.078</td> <td> 0.000</td> <td>    0.746</td> <td>    0.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_VS2</th>  <td>    0.7443</td> <td>    0.007</td> <td>  105.410</td> <td> 0.000</td> <td>    0.730</td> <td>    0.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_VVS1</th> <td>    0.9429</td> <td>    0.014</td> <td>   67.375</td> <td> 0.000</td> <td>    0.916</td> <td>    0.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity_VVS2</th> <td>    0.8762</td> <td>    0.012</td> <td>   72.099</td> <td> 0.000</td> <td>    0.852</td> <td>    0.900</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   No. Observations:                  859\n",
       "Model:                            GLM   Df Residuals:                      838\n",
       "Model Family:                Gaussian   Df Model:                           20\n",
       "Link Function:                    log   Scale:                          50649.\n",
       "Method:                          IRLS   Log-Likelihood:                -5861.0\n",
       "Date:                Wed, 08 Mar 2023   Deviance:                   4.2444e+07\n",
       "Time:                        02:23:04   Pearson chi2:                 4.24e+07\n",
       "No. Iterations:                    22   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            6.0650      0.005   1159.381      0.000       6.055       6.075\n",
       "carat           -0.5882      0.039    -14.960      0.000      -0.665      -0.511\n",
       "depth           -0.0430      0.045     -0.958      0.338      -0.131       0.045\n",
       "table            0.0243      0.004      6.350      0.000       0.017       0.032\n",
       "length_mm        0.0201      0.099      0.203      0.839      -0.174       0.215\n",
       "width_mm         0.3744      0.092      4.087      0.000       0.195       0.554\n",
       "depth_mm         0.7281      0.171      4.270      0.000       0.394       1.062\n",
       "encoded cut      0.0122      0.003      3.517      0.000       0.005       0.019\n",
       "color_D          0.9806      0.009    111.662      0.000       0.963       0.998\n",
       "color_E          0.9480      0.007    139.634      0.000       0.935       0.961\n",
       "color_F          0.9357      0.007    138.875      0.000       0.923       0.949\n",
       "color_G          0.8831      0.008    113.083      0.000       0.868       0.898\n",
       "color_H          0.8194      0.009     94.732      0.000       0.802       0.836\n",
       "color_I          0.7579      0.011     67.488      0.000       0.736       0.780\n",
       "color_J          0.7402      0.016     44.962      0.000       0.708       0.772\n",
       "clarity_I1       0.4579      0.023     20.128      0.000       0.413       0.502\n",
       "clarity_IF       0.9950      0.022     45.326      0.000       0.952       1.038\n",
       "clarity_SI1      0.6948      0.007    101.299      0.000       0.681       0.708\n",
       "clarity_SI2      0.5914      0.009     62.388      0.000       0.573       0.610\n",
       "clarity_VS1      0.7624      0.008     91.078      0.000       0.746       0.779\n",
       "clarity_VS2      0.7443      0.007    105.410      0.000       0.730       0.758\n",
       "clarity_VVS1     0.9429      0.014     67.375      0.000       0.916       0.970\n",
       "clarity_VVS2     0.8762      0.012     72.099      0.000       0.852       0.900\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = add_constant(X_PREP)  # Ading constant column to handle bias\n",
    "model_full = GLM(y, X, family=sm.families.Gaussian(sm.families.links.log()))\n",
    "res = model_full.fit()  # Fitting the model\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth\n",
      "length_mm\n"
     ]
    }
   ],
   "source": [
    "pvalues = dict(res.pvalues)  # Identifying the columns to drop\n",
    "for x in pvalues:\n",
    "    if pvalues[x] >= 0.05:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = X.drop(['depth', 'length_mm'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive Model:  yhat=5.455245+0.001909*ZN+0.022373*INDUS+0.028275*RAD-0.002238*MEDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[233.14823973272647,\n",
       " 224.86136882050604,\n",
       " 163.87127117672674,\n",
       " 162.87693038257981]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_st_full = []\n",
    "rmse_st_red = []\n",
    "rmse_skl_full = []\n",
    "rmse_skl_red = []\n",
    "\n",
    "model_skl = LinearRegression()\n",
    "for i in range(20):\n",
    "    #************************* Full Data Modelling  ***************************#\n",
    "    X = add_constant(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # statsmodels\n",
    "    model_st_full_train = GLM(y_train, X_train, family=sm.families.Gaussian(sm.families.links.log()))\n",
    "    model_st_full = model_st_full_train.fit()  # Fitting the model\n",
    "\n",
    "    # Predicting using Test-set\n",
    "    pred_st_full = model_st_full.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, pred_st_full))\n",
    "    rmse_st_full.append(rmse)\n",
    "    \n",
    "    # sklearn\n",
    "    model_skl.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting using Test-set\n",
    "    pred_skl_full = model_skl.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, pred_skl_full))\n",
    "    rmse_skl_full.append(rmse)\n",
    "    \n",
    "    #************************* Reduced Data Modelling  ***************************#\n",
    "    X = add_constant(X_red)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # statsmodels\n",
    "    model_st_red_train = GLM(y_train, X_train, family=sm.families.Gaussian(sm.families.links.log()))  # create the linear reg model using\n",
    "    model_st_red = model_st_red_train.fit()\n",
    "    \n",
    "    # Predicting using Test-set\n",
    "    pred_red = model_reduced.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, pred_red))\n",
    "    rmse_st_red.append(rmse)\n",
    "    \n",
    "    # sklearn\n",
    "    model_skl.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting using Test-set\n",
    "    pred_skl_red = model_skl.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, pred_skl_red))\n",
    "    rmse_skl_red.append(rmse)\n",
    "    \n",
    "\n",
    "[mean(rmse_st_full), mean(rmse_st_red), mean(rmse_skl_full), mean(rmse_skl_red)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(X_red)\n",
    "model_skl_red_dep = model_skl.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using Test-set\n",
    "# Predict the tax using the linear regression for the last row in the boston_house-prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2809.03468253]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "858    2871\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_st_red_dep = model_skl_red_dep.predict(X.tail(1))\n",
    "print(pred_st_red_dep)\n",
    "y.tail(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "Use boston_house price dataset, \n",
    "1.   Consider CHAS as the output variable \n",
    "2.   the remaining variables are inputs \n",
    "apply logistic regression to do the following tasks:\n",
    "*  parameter estimation \n",
    "*   attribute selection \n",
    "*  predictive model\n",
    "*   prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary library\n",
    "from statistics import mean\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import GLM, add_constant\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_csv('dataset/boston_house_prices.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CHAS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('CHAS', axis=1)  # input\n",
    "y = data['CHAS']   # output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling for feature selection / reduced model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>CHAS</td>       <th>  No. Observations:  </th>  <td>   506</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   492</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    13</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -105.75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 08 Mar 2023</td> <th>  Deviance:          </th> <td>  211.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>05:45:32</td>     <th>  Pearson chi2:      </th>  <td>  337.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.08150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>   -3.5810</td> <td>    4.939</td> <td>   -0.725</td> <td> 0.468</td> <td>  -13.262</td> <td>    6.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>    <td>   -0.2717</td> <td>    0.152</td> <td>   -1.792</td> <td> 0.073</td> <td>   -0.569</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>      <td>   -0.0018</td> <td>    0.014</td> <td>   -0.129</td> <td> 0.898</td> <td>   -0.029</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>   <td>    0.0952</td> <td>    0.042</td> <td>    2.259</td> <td> 0.024</td> <td>    0.013</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>     <td>    3.1623</td> <td>    3.174</td> <td>    0.996</td> <td> 0.319</td> <td>   -3.059</td> <td>    9.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>   -0.1114</td> <td>    0.328</td> <td>   -0.340</td> <td> 0.734</td> <td>   -0.754</td> <td>    0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>     <td>    0.0083</td> <td>    0.012</td> <td>    0.665</td> <td> 0.506</td> <td>   -0.016</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -0.0221</td> <td>    0.216</td> <td>   -0.102</td> <td> 0.918</td> <td>   -0.445</td> <td>    0.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>     <td>    0.2191</td> <td>    0.078</td> <td>    2.799</td> <td> 0.005</td> <td>    0.066</td> <td>    0.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>     <td>   -0.0087</td> <td>    0.004</td> <td>   -2.265</td> <td> 0.023</td> <td>   -0.016</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -0.1467</td> <td>    0.129</td> <td>   -1.136</td> <td> 0.256</td> <td>   -0.400</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    0.0024</td> <td>    0.004</td> <td>    0.636</td> <td> 0.525</td> <td>   -0.005</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>    0.0244</td> <td>    0.050</td> <td>    0.491</td> <td> 0.624</td> <td>   -0.073</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MEDV</th>    <td>    0.0693</td> <td>    0.032</td> <td>    2.138</td> <td> 0.032</td> <td>    0.006</td> <td>    0.133</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                   CHAS   No. Observations:                  506\n",
       "Model:                            GLM   Df Residuals:                      492\n",
       "Model Family:                Binomial   Df Model:                           13\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -105.75\n",
       "Date:                Wed, 08 Mar 2023   Deviance:                       211.49\n",
       "Time:                        05:45:32   Pearson chi2:                     337.\n",
       "No. Iterations:                     8   Pseudo R-squ. (CS):            0.08150\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -3.5810      4.939     -0.725      0.468     -13.262       6.099\n",
       "CRIM          -0.2717      0.152     -1.792      0.073      -0.569       0.026\n",
       "ZN            -0.0018      0.014     -0.129      0.898      -0.029       0.025\n",
       "INDUS          0.0952      0.042      2.259      0.024       0.013       0.178\n",
       "NOX            3.1623      3.174      0.996      0.319      -3.059       9.383\n",
       "RM            -0.1114      0.328     -0.340      0.734      -0.754       0.531\n",
       "AGE            0.0083      0.012      0.665      0.506      -0.016       0.033\n",
       "DIS           -0.0221      0.216     -0.102      0.918      -0.445       0.401\n",
       "RAD            0.2191      0.078      2.799      0.005       0.066       0.373\n",
       "TAX           -0.0087      0.004     -2.265      0.023      -0.016      -0.001\n",
       "PTRATIO       -0.1467      0.129     -1.136      0.256      -0.400       0.106\n",
       "B              0.0024      0.004      0.636      0.525      -0.005       0.010\n",
       "LSTAT          0.0244      0.050      0.491      0.624      -0.073       0.122\n",
       "MEDV           0.0693      0.032      2.138      0.032       0.006       0.133\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(X)  # add intercept\n",
    "model_logistic = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "res = model_logistic.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const\n",
      "CRIM\n",
      "ZN\n",
      "NOX\n",
      "RM\n",
      "AGE\n",
      "DIS\n",
      "PTRATIO\n",
      "B\n",
      "LSTAT\n"
     ]
    }
   ],
   "source": [
    "pvalues = dict(res.pvalues)  # Identifying the columns to drop\n",
    "for x in pvalues:\n",
    "    if pvalues[x] >= 0.05:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = X.drop(['const', 'CRIM', 'ZN', 'NOX', 'RM', 'AGE', 'DIS', 'PTRATIO', 'B', 'LSTAT'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=3)  # testset is 10%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive model based on above results:\n",
    "\n",
    "that_i = 0.0952 * INDUS_i + 0.2191 * RAD_i - 0.0087 * TAX_i + 0.0693 * MEDV_i\n",
    "\n",
    "1.   phat_i = 1 / (1 + exp(-that_i))\n",
    "2.   yhat_i = 1 if phat_i >= 0.5 else yhat_i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_st_red_train = GLM(y_train, X_train, family=sm.families.Binomial()) # logistic regression\n",
    "model_st_red = model_st_red_train.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224    0.245663\n",
       "137    0.045313\n",
       "453    0.067303\n",
       "303    0.067967\n",
       "254    0.005386\n",
       "37     0.029412\n",
       "442    0.112732\n",
       "417    0.000672\n",
       "16     0.022943\n",
       "209    0.024132\n",
       "126    0.208278\n",
       "157    0.383280\n",
       "196    0.020893\n",
       "266    0.161863\n",
       "404    0.000053\n",
       "399    0.013794\n",
       "116    0.023814\n",
       "127    0.037455\n",
       "134    0.025365\n",
       "201    0.007439\n",
       "503    0.053354\n",
       "161    0.534502\n",
       "287    0.025959\n",
       "73     0.026413\n",
       "439    0.035295\n",
       "325    0.039428\n",
       "112    0.018129\n",
       "310    0.017442\n",
       "14     0.016644\n",
       "230    0.053991\n",
       "27     0.009174\n",
       "291    0.053341\n",
       "479    0.018896\n",
       "102    0.007754\n",
       "124    0.321740\n",
       "376    0.010298\n",
       "248    0.018770\n",
       "237    0.111496\n",
       "354    0.002151\n",
       "334    0.037681\n",
       "153    0.216423\n",
       "392    0.014511\n",
       "218    0.113605\n",
       "458    0.048127\n",
       "357    0.211703\n",
       "101    0.023423\n",
       "269    0.027910\n",
       "211    0.023232\n",
       "348    0.015260\n",
       "103    0.012016\n",
       "349    0.003932\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_st_raw = model_st_red.predict(X_test)\n",
    "prediction_st_raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting predictions to binary predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction  Actual\n",
       "224           0       0\n",
       "137           0       0\n",
       "453           0       0\n",
       "303           0       0\n",
       "254           0       0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_st = [1 if prediction > 0.5 else 0 for prediction in prediction_st_raw]\n",
    "df = DataFrame({\"Prediction\": prediction_st, \"Actual\": y_test})\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_skl = LogisticRegression(max_iter=10000)\n",
    "model_skl = model_skl.fit(X_train, y_train)\n",
    "prediction_skl = model_skl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction_st</th>\n",
       "      <th>Prediction_skl</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction_st  Prediction_skl  Actual\n",
       "224              0               0       0\n",
       "137              0               0       0\n",
       "453              0               0       0\n",
       "303              0               0       0\n",
       "254              0               0       0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame({\"Prediction_st\": prediction_st, \"Prediction_skl\": prediction_skl, \"Actual\": y_test})\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute recall and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8823529411764706, 0.9019607843137255]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "# Prediction_st\n",
    "acc_st = accuracy_score(y_test, prediction_st)\n",
    "re_st = recall_score(y_test, prediction_st)\n",
    "acc_skl = accuracy_score(y_test, prediction_skl)\n",
    "re_skl = recall_score(y_test, prediction_skl)\n",
    "print([acc_st, acc_skl])\n",
    "[re_st, re_skl]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
